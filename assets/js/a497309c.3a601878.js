"use strict";(self.webpackChunkadminforth=self.webpackChunkadminforth||[]).push([[2225],{1520:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>c});var t=i(4848),s=i(8453);const r={},l="PluginOptions",o={id:"api/plugins/chat-gpt/types/interfaces/PluginOptions",title:"PluginOptions",description:"Properties",source:"@site/docs/api/plugins/chat-gpt/types/interfaces/PluginOptions.md",sourceDirName:"api/plugins/chat-gpt/types/interfaces",slug:"/api/plugins/chat-gpt/types/interfaces/PluginOptions",permalink:"/docs/api/plugins/chat-gpt/types/interfaces/PluginOptions",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"apiSidebar",previous:{title:"plugins/chat-gpt/types",permalink:"/docs/api/plugins/chat-gpt/types/"},next:{title:"plugins/email-password-reset/types",permalink:"/docs/api/plugins/email-password-reset/types/"}},d={},c=[{value:"Properties",id:"properties",level:2},{value:"expert?",id:"expert",level:3},{value:"debounceTime?",id:"debouncetime",level:4},{value:"maxTokens?",id:"maxtokens",level:4},{value:"promptInputLimit?",id:"promptinputlimit",level:4},{value:"recordContext?",id:"recordcontext",level:4},{value:"recordContext.maxFieldLength?",id:"recordcontextmaxfieldlength",level:4},{value:"recordContext.maxFields?",id:"recordcontextmaxfields",level:4},{value:"recordContext.splitParts?",id:"recordcontextsplitparts",level:4},{value:"stop?",id:"stop",level:4},{value:"temperature?",id:"temperature",level:4},{value:"fieldName",id:"fieldname",level:3},{value:"model?",id:"model",level:3},{value:"openAiApiKey",id:"openaiapikey",level:3},{value:"rateLimit?",id:"ratelimit",level:3},{value:"errorMessage",id:"errormessage",level:4},{value:"limit",id:"limit",level:4}];function p(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",hr:"hr",p:"p",strong:"strong",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"pluginoptions",children:"PluginOptions"}),"\n",(0,t.jsx)(n.h2,{id:"properties",children:"Properties"}),"\n",(0,t.jsx)(n.h3,{id:"expert",children:"expert?"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"optional"})," ",(0,t.jsx)(n.strong,{children:"expert"}),": ",(0,t.jsx)(n.code,{children:"object"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Expert settings"}),"\n",(0,t.jsx)(n.h4,{id:"debouncetime",children:"debounceTime?"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"optional"})," ",(0,t.jsx)(n.strong,{children:"debounceTime"}),": ",(0,t.jsx)(n.code,{children:"number"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Debounce time in ms. Default is 300. Time after user stopped typing before request will be sent."}),"\n",(0,t.jsx)(n.h4,{id:"maxtokens",children:"maxTokens?"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"optional"})," ",(0,t.jsx)(n.strong,{children:"maxTokens"}),": ",(0,t.jsx)(n.code,{children:"number"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Number of tokens to generate. Default is 50. 1 token ~= \xbe words"}),"\n",(0,t.jsx)(n.h4,{id:"promptinputlimit",children:"promptInputLimit?"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"optional"})," ",(0,t.jsx)(n.strong,{children:"promptInputLimit"}),": ",(0,t.jsx)(n.code,{children:"number"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Maximum number of last characters which will be used for completion for target field. Default is 500.\nHigher value will give better context but will cost more."}),"\n",(0,t.jsx)(n.h4,{id:"recordcontext",children:"recordContext?"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"optional"})," ",(0,t.jsx)(n.strong,{children:"recordContext"}),": ",(0,t.jsx)(n.code,{children:"object"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"When completion is made, this plugin passes non-empty fields of the record to the LLM model for record context understanding."}),"\n",(0,t.jsx)(n.h4,{id:"recordcontextmaxfieldlength",children:"recordContext.maxFieldLength?"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"optional"})," ",(0,t.jsx)(n.strong,{children:"maxFieldLength"}),": ",(0,t.jsx)(n.code,{children:"number"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Limit of input field value. Default is 300. If field is longer, it will be truncated."}),"\n",(0,t.jsx)(n.h4,{id:"recordcontextmaxfields",children:"recordContext.maxFields?"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"optional"})," ",(0,t.jsx)(n.strong,{children:"maxFields"}),": ",(0,t.jsx)(n.code,{children:"number"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Using this field you can limit number of fields passed to the model.\nDefault is 5.\nCompletion field is not included in this limit.\nSet to 0 to disable context passing at all.\nIf count of fields exceeds this number, longest fields will be selected.\nIf some of values will exceed maxFieldLength, it will be smartly truncated by splitting ito splitParts, taking their\nstarting substring and joining back with '...'."}),"\n",(0,t.jsx)(n.h4,{id:"recordcontextsplitparts",children:"recordContext.splitParts?"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"optional"})," ",(0,t.jsx)(n.strong,{children:"splitParts"}),": ",(0,t.jsx)(n.code,{children:"number"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"How many parts to split field value if it exceeds maxFieldLength. Default is 5."}),"\n",(0,t.jsx)(n.h4,{id:"stop",children:"stop?"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"optional"})," ",(0,t.jsx)(n.strong,{children:"stop"}),": ",(0,t.jsx)(n.code,{children:"string"}),"[]"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Stop tokens. Default is ['.']"}),"\n",(0,t.jsx)(n.h4,{id:"temperature",children:"temperature?"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"optional"})," ",(0,t.jsx)(n.strong,{children:"temperature"}),": ",(0,t.jsx)(n.code,{children:"number"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Temperature (0-1). Lower is more deterministic, higher is more unpredicted creative. Default is 0.7."}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"fieldname",children:"fieldName"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"fieldName"}),": ",(0,t.jsx)(n.code,{children:"string"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Field where plugin will auto-complete text. Should be string or text field."}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"model",children:"model?"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"optional"})," ",(0,t.jsx)(n.strong,{children:"model"}),": ",(0,t.jsx)(n.code,{children:"string"})]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Model name. Go to ",(0,t.jsx)(n.a,{href:"https://platform.openai.com/docs/models",children:"https://platform.openai.com/docs/models"}),", select model and copy name.\nDefault is ",(0,t.jsx)(n.code,{children:"gpt-4o-mini"}),". Use e.g. more expensive ",(0,t.jsx)(n.code,{children:"gpt-4o"})," for more powerful model."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"openaiapikey",children:"openAiApiKey"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"openAiApiKey"}),": ",(0,t.jsx)(n.code,{children:"string"})]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["OpenAI API key. Go to ",(0,t.jsx)(n.a,{href:"https://platform.openai.com/",children:"https://platform.openai.com/"}),", go to Dashboard -> API keys -> Create new secret key\nPaste value in your .env file OPENAI_API_KEY=your_key\nSet openAiApiKey: process.env.OPENAI_API_KEY to access it"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"ratelimit",children:"rateLimit?"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"optional"})," ",(0,t.jsx)(n.strong,{children:"rateLimit"}),": ",(0,t.jsx)(n.code,{children:"object"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Since AI generation can be expensive, we can limit the number of requests per IP.\nCompletion will simply stop working when limit is reached so user will not be bothered with error messages."}),"\n",(0,t.jsx)(n.h4,{id:"errormessage",children:"errorMessage"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"errorMessage"}),": ",(0,t.jsx)(n.code,{children:"string"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Message shown to user when rate limit is reached"}),"\n",(0,t.jsx)(n.h4,{id:"limit",children:"limit"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"limit"}),": ",(0,t.jsx)(n.code,{children:"string"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"E.g. 5/1d - 5 requests per day\n3/1h - 3 requests per hour"})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var t=i(6540);const s={},r=t.createContext(s);function l(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);
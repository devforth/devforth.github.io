"use strict";(self.webpackChunkadminforth=self.webpackChunkadminforth||[]).push([[7449],{177:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>p,frontMatter:()=>o,metadata:()=>r,toc:()=>l});var r=t(1378),s=t(4848),a=t(8453);const o={slug:"compose-ec2-deployment-github-actions",title:"Deploy AdminForth to EC2 with terraform on CI",authors:"ivanb",tags:["aws","terraform","github-actions"]},i=void 0,c={authorsImageUrls:[void 0]},l=[{value:"Step 1 - Dockerfile",id:"step-1---dockerfile",level:2},{value:"Step 2 - compose.yml",id:"step-2---composeyml",level:2},{value:"Step 3 - create a SSH keypair",id:"step-3---create-a-ssh-keypair",level:2},{value:"Step 4 - .gitignore file",id:"step-4---gitignore-file",level:2},{value:"Step 5 - Main terraform file main.tf",id:"step-5---main-terraform-file-maintf",level:2},{value:"Step 5.1 - Configure AWS Profile",id:"step-51---configure-aws-profile",level:3},{value:"Step 5.2 - Run deployment",id:"step-52---run-deployment",level:3},{value:"Step 6 - Migrate state to the cloud",id:"step-6---migrate-state-to-the-cloud",level:2},{value:"Step 7 - CI/CD - Github Actions",id:"step-7---cicd---github-actions",level:2},{value:"Step 7.1 - Create deploy script",id:"step-71---create-deploy-script",level:3},{value:"Step 7.2 - Add secrets to GitHub",id:"step-72---add-secrets-to-github",level:3}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"Here is more advanced snippet to deploy AdminForth to Terraform."}),"\n",(0,s.jsx)(n.p,{children:"Here Terraform state will be stored in the cloud, so you can run this deployment from any machine including stateless CI/CD."}),"\n",(0,s.jsx)(n.p,{children:"We will use GitHub Actions as CI/CD, but you can use any other CI/CD, for example self-hosted free WoodpeckerCI."}),"\n",(0,s.jsxs)(n.p,{children:["Assume you have your AdminForth project in ",(0,s.jsx)(n.code,{children:"myadmin"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"step-1---dockerfile",children:"Step 1 - Dockerfile"}),"\n",(0,s.jsxs)(n.p,{children:["Create file ",(0,s.jsx)(n.code,{children:"Dockerfile"})," in ",(0,s.jsx)(n.code,{children:"myadmin"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Dockerfile",metastring:'title="./myadmin/Dockerfile"',children:'# use the same node version which you used during dev\nFROM node:20-alpine\nWORKDIR /code/\nADD package.json package-lock.json /code/\nRUN npm ci  \nADD . /code/\nRUN --mount=type=cache,target=/tmp npx tsx bundleNow.ts\nCMD ["npm", "run", "startLive"]\n'})}),"\n",(0,s.jsx)(n.h2,{id:"step-2---composeyml",children:"Step 2 - compose.yml"}),"\n",(0,s.jsxs)(n.p,{children:["create folder ",(0,s.jsx)(n.code,{children:"deploy"})," and create file ",(0,s.jsx)(n.code,{children:"compose.yml"})," inside:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yml",metastring:'title="deploy/compose.yml"',children:'\nservices:\n  traefik:\n    image: "traefik:v2.5"\n    command:\n      - "--api.insecure=true"\n      - "--providers.docker=true"\n      - "--entrypoints.web.address=:80"\n    ports:\n      - "80:80"\n    volumes:\n      - "/var/run/docker.sock:/var/run/docker.sock:ro"\n\n  myadmin:\n    build: ./myadmin\n    restart: always\n    env_file:\n      - ./myadmin/.env\n    volumes:\n      - myadmin-db:/code/db\n    labels:\n      - "traefik.enable=true"\n      - "traefik.http.routers.myadmin.rule=PathPrefix(`/`)"\n      - "traefik.http.services.myadmin.loadbalancer.server.port=3500"\n      - "traefik.http.routers.myadmin.priority=2"\n\nvolumes:\n  myadmin-db:\n'})}),"\n",(0,s.jsx)(n.h2,{id:"step-3---create-a-ssh-keypair",children:"Step 3 - create a SSH keypair"}),"\n",(0,s.jsxs)(n.p,{children:["Make sure you are in ",(0,s.jsx)(n.code,{children:"deploy"})," folder, run next command here:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",metastring:'title="deploy"',children:'mkdir .keys && ssh-keygen -f .keys/id_rsa -N ""\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Now it should create ",(0,s.jsx)(n.code,{children:"deploy/.keys/id_rsa"})," and ",(0,s.jsx)(n.code,{children:"deploy/.keys/id_rsa.pub"})," files with your SSH keypair. Terraform script will put the public key to the EC2 instance and will use private key to connect to the instance. Also you will be able to use it to connect to the instance manually."]}),"\n",(0,s.jsx)(n.h2,{id:"step-4---gitignore-file",children:"Step 4 - .gitignore file"}),"\n",(0,s.jsxs)(n.p,{children:["Create ",(0,s.jsx)(n.code,{children:"deploy/.gitignore"})," file with next content:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:".terraform/\n.keys/\n*.tfstate\n*.tfstate.*\n*.tfvars\ntfplan\n"})}),"\n",(0,s.jsx)(n.h2,{id:"step-5---main-terraform-file-maintf",children:"Step 5 - Main terraform file main.tf"}),"\n",(0,s.jsxs)(n.p,{children:["First of all install Terraform as described here ",(0,s.jsx)(n.a,{href:"https://developer.hashicorp.com/terraform/install#linux",children:"terraform installation"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["Create file ",(0,s.jsx)(n.code,{children:"main.tf"})," in ",(0,s.jsx)(n.code,{children:"deploy"})," folder:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-hcl",metastring:'title="deploy/main.tf"',children:'\nlocals {\n  app_name = "<your_app_name>"\n  aws_region = "eu-central-1"\n}\n\n\nprovider "aws" {\n  region = local.aws_region\n  profile = "myaws"\n}\n\ndata "aws_ami" "ubuntu_linux" {\n  most_recent = true\n  owners      = ["amazon"]\n\n  filter {\n    name   = "name"\n    values = ["ubuntu/images/hvm-ssd-gp3/ubuntu-noble-24.04-amd64-server-*"]\n  }\n}\n\ndata "aws_vpc" "default" {\n  default = true\n}\n\n\nresource "aws_eip" "eip" {\n domain = "vpc"\n}\nresource "aws_eip_association" "eip_assoc" {\n instance_id   = aws_instance.app_instance.id\n allocation_id = aws_eip.eip.id\n}\n\ndata "aws_subnet" "default_subnet" {\n  filter {\n    name   = "vpc-id"\n    values = [data.aws_vpc.default.id]\n  }\n\n  filter {\n    name   = "default-for-az"\n    values = ["true"]\n  }\n\n  filter {\n    name   = "availability-zone"\n    values = ["${local.aws_region}a"]\n  }\n}\n\nresource "aws_security_group" "instance_sg" {\n  name   = "${local.app_name}-instance-sg"\n  vpc_id = data.aws_vpc.default.id\n\n  ingress {\n    description = "Allow HTTP"\n    from_port   = 80\n    to_port     = 80\n    protocol    = "tcp"\n    cidr_blocks = ["0.0.0.0/0"]\n  }\n\n  # SSH\n  ingress {\n    description = "Allow SSH"\n    from_port   = 22\n    to_port     = 22\n    protocol    = "tcp"\n    cidr_blocks = ["0.0.0.0/0"]\n  }\n\n  egress {\n    description = "Allow all outbound traffic"\n    from_port   = 0\n    to_port     = 0\n    protocol    = "-1"\n    cidr_blocks = ["0.0.0.0/0"]\n  }\n}\n\nresource "aws_key_pair" "app_deployer" {\n  key_name   = "terraform-deploy_${local.app_name}-key"\n  public_key = file("./.keys/id_rsa.pub") # Path to your public SSH key\n}\n\nresource "aws_instance" "app_instance" {\n  ami                    = data.aws_ami.ubuntu_linux.id\n  instance_type          = "t3a.small"\n  subnet_id              = data.aws_subnet.default_subnet.id\n  vpc_security_group_ids = [aws_security_group.instance_sg.id]\n  key_name               = aws_key_pair.app_deployer.key_name\n\n  # prevent accidental termination of ec2 instance and data loss\n  # if you will need to recreate the instance still (not sure why it can be?), you will need to remove this block manually by next command:\n  # > terraform taint aws_instance.app_instance\n  lifecycle {\n    prevent_destroy = true\n    ignore_changes = [ami]\n  }\n\n  root_block_device {\n    volume_size = 20 // Size in GB for root partition\n    volume_type = "gp2"\n\n    # Even if the instance is terminated, the volume will not be deleted, delete it manually if needed\n    delete_on_termination = false\n  }\n\n  user_data = <<-EOF\n    #!/bin/bash\n    sudo apt-get update\n    sudo apt-get install ca-certificates curl\n    sudo install -m 0755 -d /etc/apt/keyrings\n    sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\n    sudo chmod a+r /etc/apt/keyrings/docker.asc\n\n    # Add the repository to Apt sources:\n    echo \\\n      "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n      $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \\\n      sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n    sudo apt-get update\n\n    sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n\n    systemctl start docker\n    systemctl enable docker\n    usermod -a -G docker ubuntu\n  EOF\n\n  tags = {\n    Name = "${local.app_name}-instance"\n  }\n}\n\nresource "null_resource" "sync_files_and_run" {\n  # Use rsync to exclude node_modules, .git, db\n  provisioner "local-exec" {\n    # heredoc syntax\n    # remove files that where deleted on the source\n    command = <<-EOF\n    #  -o StrictHostKeyChecking=no\n    rsync -t -av -e "ssh -i ./.keys/id_rsa -o StrictHostKeyChecking=no" \\\n      --delete \\\n      --exclude \'node_modules\' \\\n      --exclude \'.git\' \\\n      --exclude \'.terraform\' \\\n      --exclude \'terraform*\' \\\n      --exclude \'tfplan\' \\\n      --exclude \'.keys\' \\\n      --exclude \'.vscode\' \\\n      --exclude \'.env\' \\\n      --exclude \'db\' \\\n      ../ ubuntu@${aws_eip_association.eip_assoc.public_ip}:/home/ubuntu/app/\n    EOF\n  }\n\n  # Run docker compose after files have been copied\n  provisioner "remote-exec" {\n    inline = [\n      # fail bash specially and intentionally to stop the script on error\n      "bash -c \'while ! command -v docker &> /dev/null; do echo \\"Waiting for Docker to be installed...\\"; sleep 1; done\'",\n      "bash -c \'while ! docker info &> /dev/null; do echo \\"Waiting for Docker to start...\\"; sleep 1; done\'",\n      \n      # please note that prune might destroy build cache and make build slower, however it releases disk space\n      "docker system prune -f",\n      # "docker buildx prune -f --filter \'type!=exec.cachemount\'",\n      "cd /home/ubuntu/app/deploy",\n      # COMPOSE_FORCE_NO_TTY is needed to run docker compose in non-interactive mode and prevent stdout mess up\n      "COMPOSE_FORCE_NO_TTY=1 docker compose -p app -f compose.yml up --build -d"\n    ]\n\n    connection {\n      type        = "ssh"\n      user        = "ubuntu"\n      private_key = file("./.keys/id_rsa")\n      host        = aws_eip_association.eip_assoc.public_ip\n    }\n  }\n\n  # Ensure the resource is triggered every time based on timestamp or file hash\n  triggers = {\n    always_run = timestamp()\n  }\n\n  depends_on = [aws_instance.app_instance, aws_eip_association.eip_assoc]\n}\n\n\noutput "instance_public_ip" {\n  value = aws_eip_association.eip_assoc.public_ip\n}\n\n\n######### This scetion is for tf state storage ##############\n\n# S3 bucket for storing Terraform state\nresource "aws_s3_bucket" "terraform_state" {\n  bucket = "${local.app_name}-terraform-state"\n}\n\nresource "aws_s3_bucket_lifecycle_configuration" "terraform_state" {\n  bucket = aws_s3_bucket.terraform_state.bucket\n\n  rule {\n    status = "Enabled"\n    id = "Keep only the latest version of the state file"\n\n    noncurrent_version_expiration {\n      noncurrent_days = 30\n    }\n  }\n}\n\nresource "aws_s3_bucket_versioning" "terraform_state" {\n  bucket = aws_s3_bucket.terraform_state.bucket\n\n  versioning_configuration {\n    status = "Enabled"\n  }\n}\n\nresource "aws_s3_bucket_server_side_encryption_configuration" "terraform_state" {\n  bucket = aws_s3_bucket.terraform_state.bucket\n\n  rule {\n    apply_server_side_encryption_by_default {\n      sse_algorithm     = "AES256"\n    }\n  }\n}\n\n\n'})}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:["\ud83d\udc46 Replace ",(0,s.jsx)(n.code,{children:"<your_app_name>"})," with your app name (no spaces, only underscores or letters)"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"step-51---configure-aws-profile",children:"Step 5.1 - Configure AWS Profile"}),"\n",(0,s.jsx)(n.p,{children:"Open or create file ~/.aws/credentials and add (if not already there):"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ini",children:"[myaws]\naws_access_key_id = <your_access_key>\naws_secret_access_key = <your_secret_key>\n"})}),"\n",(0,s.jsx)(n.h3,{id:"step-52---run-deployment",children:"Step 5.2 - Run deployment"}),"\n",(0,s.jsx)(n.p,{children:"To run the deployment first time, you need to run:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"terraform init\n"})}),"\n",(0,s.jsx)(n.p,{children:"Now run deployement:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"terraform apply -auto-approve\n"})}),"\n",(0,s.jsx)(n.h2,{id:"step-6---migrate-state-to-the-cloud",children:"Step 6 - Migrate state to the cloud"}),"\n",(0,s.jsx)(n.p,{children:"First deployment had to create S3 bucket and DynamoDB table for storing Terraform state. Now we need to migrate the state to the cloud."}),"\n",(0,s.jsxs)(n.p,{children:["Add to the end of ",(0,s.jsx)(n.code,{children:"main.tf"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-hcl",metastring:'title="main.tf"',children:'\n# Configure the backend to use the S3 bucket and DynamoDB table\nterraform {\n backend "s3" {\n   bucket         = "<your_app_name>-terraform-state"\n   key            = "state.tfstate"  # Define a specific path for the state file\n   region         = "eu-central-1"\n   profile        = "myaws"\n   dynamodb_table = "<your_app_name>-terraform-lock-table"\n   use_lockfile   = true\n }\n}\n'})}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:["\ud83d\udc46 Replace ",(0,s.jsx)(n.code,{children:"<your_app_name>"})," with your app name (no spaces, only underscores or letters).\nUnfortunately we can't use variables, HashiCorp thinks it is too dangerous \ud83d\ude25"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Now run:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"terraform init -migrate-state\n"})}),"\n",(0,s.jsx)(n.p,{children:"Now run test deployment:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"terraform apply -auto-approve\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Now you can delete local ",(0,s.jsx)(n.code,{children:"terraform.tfstate"})," file and ",(0,s.jsx)(n.code,{children:"terraform.tfstate.backup"})," file as they are in the cloud now."]}),"\n",(0,s.jsx)(n.h2,{id:"step-7---cicd---github-actions",children:"Step 7 - CI/CD - Github Actions"}),"\n",(0,s.jsxs)(n.p,{children:["Create file ",(0,s.jsx)(n.code,{children:".github/workflows/deploy.yml"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yml",metastring:'title=".github/workflows/deploy.yml"',children:'name: Deploy \nrun-name: ${{ github.actor }} builds app \ud83d\ude80\non: [push]\njobs:\n  Explore-GitHub-Actions:\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo "\ud83c\udf89 The job was automatically triggered by a ${{ github.event_name }} event."\n      - run: echo "\ud83d\udc27 This job is now running on a ${{ runner.os }} server"\n      - run: echo "\ud83d\udd0e The name of your branch is ${{ github.ref }}"\n      - name: Check out repository code\n        uses: actions/checkout@v4\n      - name: Set up Terraform\n        uses: hashicorp/setup-terraform@v2\n        with:\n          terraform_version: 1.4.6  \n      - run: echo "\ud83d\udca1 The ${{ github.repository }} repository has been cloned to the runner."\n      - name: Start building\n        env:\n          VAULT_AWS_ACCESS_KEY_ID: ${{ secrets.VAULT_AWS_ACCESS_KEY_ID }}\n          VAULT_AWS_SECRET_ACCESS_KEY: ${{ secrets.VAULT_AWS_SECRET_ACCESS_KEY }}\n          VAULT_SSH_PRIVATE_KEY: ${{ secrets.VAULT_SSH_PRIVATE_KEY }}\n          VAULT_SSH_PUBLIC_KEY: ${{ secrets.VAULT_SSH_PUBLIC_KEY }}\n        run: |\n          /bin/sh -x deploy/deploy.sh\n          \n      - run: echo "\ud83c\udf4f This job\'s status is ${{ job.status }}."\n'})}),"\n",(0,s.jsx)(n.h3,{id:"step-71---create-deploy-script",children:"Step 7.1 - Create deploy script"}),"\n",(0,s.jsxs)(n.p,{children:["Now create file ",(0,s.jsx)(n.code,{children:"deploy/deploy.sh"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",metastring:'title="deploy/deploy.sh"',children:'\n# cd to dir of script\ncd "$(dirname "$0")"\n\nmkdir -p ~/.aws ./.keys\n\ncat <<EOF > ~/.aws/credentials\n[myaws]\naws_access_key_id=$VAULT_AWS_ACCESS_KEY_ID\naws_secret_access_key=$VAULT_AWS_SECRET_ACCESS_KEY\nEOF\n\ncat <<EOF > ./.keys/id_rsa\n$VAULT_SSH_PRIVATE_KEY\nEOF\n\ncat <<EOF > ./.keys/id_rsa.pub\n$VAULT_SSH_PUBLIC_KEY\nEOF\n\nchmod 600 ./.keys/id_rsa*\n\n# force Terraform to reinitialize the backend without migrating the state.\nterraform init -reconfigure\nterraform plan -out=tfplan\nterraform apply tfplan\n'})}),"\n",(0,s.jsx)(n.h3,{id:"step-72---add-secrets-to-github",children:"Step 7.2 - Add secrets to GitHub"}),"\n",(0,s.jsxs)(n.p,{children:["Go to your GitHub repository, then ",(0,s.jsx)(n.code,{children:"Settings"})," -> ",(0,s.jsx)(n.code,{children:"Secrets"})," -> ",(0,s.jsx)(n.code,{children:"New repository secret"})," and add:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"VAULT_AWS_ACCESS_KEY_ID"})," - your AWS access key"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"VAULT_AWS_SECRET_ACCESS_KEY"})," - your AWS secret key"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"VAULT_SSH_PRIVATE_KEY"})," - make ",(0,s.jsx)(n.code,{children:"cat ~/.ssh/id_rsa"})," and paste to GitHub secrets"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"VAULT_SSH_PUBLIC_KEY"})," - make ",(0,s.jsx)(n.code,{children:"cat ~/.ssh/id_rsa.pub"})," and paste to GitHub secrets"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Now you can push your changes to GitHub and see how it will be deployed automatically."})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>i});var r=t(6540);const s={},a=r.createContext(s);function o(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(a.Provider,{value:n},e.children)}},1378:e=>{e.exports=JSON.parse('{"permalink":"/blog/compose-ec2-deployment-github-actions","source":"@site/blog/2024-11-14-compose-ec2-deployment-ci/index.md","title":"Deploy AdminForth to EC2 with terraform on CI","description":"Here is more advanced snippet to deploy AdminForth to Terraform.","date":"2024-11-14T00:00:00.000Z","tags":[{"inline":false,"label":"AWS","permalink":"/blog/tags/aws","description":"Amazon Web Services (AWS) is a cloud computing platform that provides a wide range of services for building and deploying applications."},{"inline":false,"label":"Terraform","permalink":"/blog/tags/terraform","description":"Terraform is an open-source infrastructure as code software tool created by HashiCorp that enables users to define and provision data center infrastructure using a declarative configuration language."},{"inline":false,"label":"GitHub Actions","permalink":"/blog/tags/github-actions","description":"GitHub Actions is a continuous integration and continuous deployment (CI/CD) service provided by GitHub that allows you to automate your software development workflows."}],"readingTime":7.545,"hasTruncateMarker":true,"authors":[{"name":"Ivan Borshcho","title":"Maintainer of AdminForth","url":"https://github.com/ivictbor","imageURL":"https://avatars.githubusercontent.com/u/1838656?v=4","key":"ivanb","page":null}],"frontMatter":{"slug":"compose-ec2-deployment-github-actions","title":"Deploy AdminForth to EC2 with terraform on CI","authors":"ivanb","tags":["aws","terraform","github-actions"]},"unlisted":false,"prevItem":{"title":"Backup database to AWS Glacier","permalink":"/blog/backup-database-to-aws-glacier"},"nextItem":{"title":"Deploy AdminForth to EC2 with terraform (without CI)","permalink":"/blog/compose-ec2-deployment"}}')}}]);
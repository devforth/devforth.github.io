"use strict";(self.webpackChunkadminforth=self.webpackChunkadminforth||[]).push([[8749],{1895:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"how-we-manage-versions","metadata":{"permalink":"/blog/how-we-manage-versions","source":"@site/blog/2025-01-19-how-adminforth-manages-version/index.md","title":"Why manual releases and release notes is a chaos and how to fix it","description":"Learn what profits you can get from automatic versioning and learn how simply you can configure it!","date":"2025-01-19T00:00:00.000Z","tags":[{"inline":true,"label":"git","permalink":"/blog/tags/git"},{"inline":true,"label":"versioning","permalink":"/blog/tags/versioning"}],"readingTime":11.855,"hasTruncateMarker":false,"authors":[{"name":"Ivan Borshcho","title":"Maintainer of AdminForth","url":"https://github.com/ivictbor","imageURL":"https://avatars.githubusercontent.com/u/1838656?v=4","key":"ivanb","page":null}],"frontMatter":{"slug":"how-we-manage-versions","title":"Why manual releases and release notes is a chaos and how to fix it","description":"Learn what profits you can get from automatic versioning and learn how simply you can configure it!","authors":"ivanb","tags":["git","versioning"]},"unlisted":false,"nextItem":{"title":"Backup database to AWS Glacier","permalink":"/blog/backup-database-to-aws-glacier"}},"content":"I have a feeling that after first ~600 versions of Adminforth we faced all possible issues with manual versioning and release notes. \\n\\nManual versioning and CHANGELOG.md is unreliable as human beings are. It is pretty easy to forget it with relevant information, forget to include some changes, forget to push it to GitHub, push it at wrong time, and many more things.\\n\\nThat is why we decided to move the idea of generating versions, and GitHub releases from git commit messages using great tool called [semantic-release](https://semantic-release.gitbook.io/semantic-release/usage/configuration).\\n\\nIn this post I will explain why we did a transition from manual releases to automatic, what profits we got from it, and also will show you simple example how to do it in your project!\\n\\n## Prehistory and issues\\n\\nBefore 1.6.0 AdminForth was using manual CHANGELOG.md. \\n\\nDuring development we were reviwing PRs, merged them all to `main` branch, pulled to local machine and there did manually npm release which also created a git tag and pushed it to GitHub.\\n\\nWe were constantly releasing to `next` pre-release version from `main` and used `next` internally on our projets for testing. \\n\\n### What is npm pre-release version?\\n\\nIf you are not familiar with pre-release versions, I can explain it on simple example.\\n\\nIf you have version `1.2.3` in your `package.json` and you run `npm version patch` it will bump version to `1.2.4`. If you run it again it will bump version to `1.2.5`.\\nIf you have version `1.2.3` and run `npm version prerelease --preid=next` it will bump version to `1.2.4-next.0`. If you run it again it will bump version to `1.2.4-next.1`. If you run `npm version patch` now it will release version `1.2.4`, hoever if at last step you run `npm version minor` it would release version `1.3.0`.\\n\\nPlease pay attention that `npm` is pretty smart and aligned with normal software release cycle -- once you run `npm version pre-release` on stable version, it understands that you start working on new version and will bump patch version. Once you run `npm version patch` at pre-release version, it will release it as stable version without bumping patch number.\\n\\nThis is very useful because we can collect features and fixes in `next` version without releasing them to `latest` version, so users who do `npm install adminforth` will not get new experimental features and fixes, but thouse who want to test them early can do `npm install adminforth@next`. Our team also using `next` for commercial projects to test new features so in the end of the day we have more stable `latest` version.\\n\\nIn new automatic release process we preserved this approach, but made it in separate git branches.\\n\\nOnce we collected enough features and fixes in `next`, we were doing a release to `latest` version, and at this time we did release documentation. \\n\\n### Issue one -- easy to forget add something to CHANGELOG.md\\n\\nSo when I merged PRs to `main` branch, I had to check commits and write them to CHANGELOG.md. \\n\\nAt this point I wasted time to understand how to call the change in CHANGELOG.md, and categorize it as `Added`, `Changed`, `Fixed`, `Removed`, `Security`.\\n\\nAlso there was a chance that I will skip some commit, or will understand wrong what it was about.\\n\\n### Issue two -- CHANGELOG.md might be forgot to be changed before release as all\\n\\nThere was a chance that I will forget to update `CHANGELOG.md` at all. I merged PRs, I am hurry and doing release. \\n\\nSometimes I will soon understand that I forgot to update it and will push it to GitHub. It will born another dump commit message like \\"Update a CHANGELOG.md\\". \\n\\nAlso I am not sure that users are looking into `main` branch to see CHANGELOG, probably they see it in npmjs.com.\\n\\n### Issue three -- lack of GitHub releases or need to maintain both\\n\\nWe did not have GitHub releases at all at that time. We had only tags. And tags were applied only after release.\\n\\nBut honestly, when I am by myself working with some pacakge, first try to find GitHub releases, though CHANGELOG.md.\\n\\nSo if I would add GitHub releases, I would have to do a lot of clicks or would need some script / CLI to create release notes. This process would have similar issues as with CHANGELOG.md.\\n\\n### Issue four -- manual tags\\n\\nSince release was manual from my PC there was a chance that I will do some minor fix, will forget to commit it, then will do release and release script will add tag to previous, irrelevant commit. \\n\\nIn such projects with manual tags, there is only one reliabile way for package user to to check what is difference in source code between two versions: using some tool like https://npmdiff.dev/ and not rely on git and CHANGELOG\\n\\nSince git tags were applied only after release and there again was a chance that I will forget to push them to GitHub with a release.\\n\\n### Issue five -- dump commits\\n\\nSince with every manual release we updated CHANGELOG.md and updated version in `pacakge.json` every time, we had to do a commit. \\n\\nSo it borned a lot of dump commits like \\"Update CHANGELOG.md\\", \\"Update version to 1.2.3\\", \\"Update version to 1.2.4\\", \\"Update version to 1.2.5\\".\\n\\nSometime it wass forgot to be commited separately and was commited with other changes in some fix which is even worsen.\\n\\n### Issue six -- releae delay and bus-factor\\n\\nSo if I was busy new features were waiting for release, becuase only I had access to do releases.\\n\\nSonner I passed access to some of my colleagues to do releases but from time to time it caused state desync and release issues between our PCs if someone forgot to push something to GitHub after release.\\n\\nEven couple of release contrubuters are onboard, it still takes a time to do all the stuff with Changelog, version, tags, etc, so it delays release.\\n\\n### Issue seven -- lack of pre-release versions changes\\n\\nWhile we releasing to `next` we added items under one version in CHANGELOG for simplicity. It would be another extra time to add every `next` version in CHANGELOG and describe whole markdown for it. \\n\\nSo user was not able to distinguish `1.5.0-next.0` from `1.5.0-next.1` in CHANGELOG, which was not an issue for `latest` users but issue for `next` users.\\n\\n\\n## Semantic-release -- what is it and how it works\\n\\n`semantic-release` is a tool that solved all issues above. Basically it is a CLI tool that you run on your CI/CD server on every push to your repository. \\n\\nSo on every push it analyzes commit messages from previous release and does next things:\\n\\n- It understands what type of release it should do: major, minor, patch, pre-release depending on commit messages. E.g. if you have a commit message `feat: add new feature` it will do a minor release, if you have `fix: fix bug` it will do a patch release.\\n- It reads previous version from git tags and does a new version based on type of release. So it does not edit `package.json` file.\\n- It generates a GitHub tag and release notes based on commit messages. So you do not need to write CHANGELOG.md anymore.\\n- It publishes a new version to npmjs.com. So you do not need to do `npm publish` anymore.\\n- It is capable to release to `next` channel from separate `next` branch without version bumping. So you can collect features and fixes in `next` without releasing them to `latest`.\\n- It has plugins, for example to send Slack notifications about releases.\\n\\nThe sweet thing that it is all executed on CI/CD server, so you do not need to do anything manually.\\n\\n\\n## Ussage example\\n\\nI will show a flow on empty fake small project to not overcomplicate things. \\n\\nThis will allow you to apply it to your project once you ready.\\n\\nWe will use minimal typescript package with `npm` and `semantic-release` to show how it works.\\n\\nFirst init new git repository:\\n\\n```bash\\necho \\"# test-sem-release\\" >> README.md\\ngit init\\ngit add README.md\\ngit commit -m \\"first commit\\"\\ngit branch -M main\\ngit remote add origin git@github.com:devforth/test-sem-release.git\\ngit push -u origin main\\n```\\n\\nNow lets init new `npm package`:\\n\\n```bash\\nnpm init -y\\nnpm install typescript --save-dev\\nnpx tsc --init\\n```\\n\\nCreate a file `index.ts`:\\n\\n```typescript title=\\"index.ts\\"\\nexport const greet = (name: string): string => {\\n  return `Hello, ${name}!`;\\n};\\n```\\n\\n\\nIn `package.json` add:\\n\\n```json\\n{\\n  \\"name\\": \\"@devforth/test-sem-release\\",\\n//diff-add\\n  \\"publishConfig\\": {\\n//diff-add\\n    \\"access\\": \\"public\\"\\n//diff-add\\n  },\\n  \\"version\\": \\"1.0.0\\",\\n  \\"main\\": \\"index.js\\",\\n  \\"scripts\\": {\\n    \\"test\\": \\"echo \\\\\\"Error: no test specified\\\\\\" && exit 1\\"\\n//diff-add\\n    \\"build\\": \\"tsc\\",\\n  },\\n  \\"author\\": \\"\\",\\n  \\"license\\": \\"ISC\\",\\n  \\"description\\": \\"\\",\\n//diff-add\\n  \\"release\\": {\\n//diff-add\\n    \\"branches\\": [\\n//diff-add\\n      \\"main\\",\\n//diff-add\\n      {\\n//diff-add\\n        \\"name\\": \\"next\\",\\n//diff-add\\n        \\"prerelease\\": true\\n//diff-add\\n      }\\n//diff-add\\n    ],\\n//diff-add\\n    \\"plugins\\": [\\n//diff-add\\n      \\"@semantic-release/commit-analyzer\\",\\n//diff-add\\n      \\"@semantic-release/release-notes-generator\\",\\n//diff-add\\n      \\"@semantic-release/npm\\",\\n//diff-add\\n      \\"@semantic-release/github\\"\\n//diff-add\\n    ],\\n//diff-add\\n  }\\n}\\n```\\n\\nMake sure name in `package.json` has your organisation name like mine `@devforth/` and you have access to publish packages to npmjs.com.\\n\\n\\nAlso install `semantic-release`:\\n\\n```bash\\nnpm i -D semantic-release\\n```\\n\\n\\n## Connecting to CI\\n\\nWe will use Woodpecker CI for this example. Woodpecker is a free and open-source CI/CD tool that you can install to your own server / VPS and will not need to pay for build minutes, and will only for server. No limits on pipelines, users, repositories, etc. If you want to try it, we have [Woodpecker installation guide](https://devforth.io/blog/step-by-step-guide-to-modern-secure-ci-setup/)\\n\\nCreate a file `.woodpecker.yml` in `deploy` directory:\\n\\n```yaml title=\\"deploy/.woodpecker.yml\\"\\nclone:\\n  git:\\n    image: woodpeckerci/plugin-git\\n    settings:\\n      partial: false\\n      depth: 5\\n\\nsteps:\\n  release:\\n    image: node:22\\n    when:\\n      - event: push\\n    commands:\\n      - npm clean-install\\n      - npm run build\\n      - npm audit signatures\\n      - npx semantic-release\\n    secrets:\\n      - GITHUB_TOKEN\\n      - NPM_TOKEN\\n```\\n\\nGo to Woodpecker, authorize via GitHub, click `Add repository`, find your repository and add it.\\n\\nDisable `Project settings` -> `Allow Pull Requests` because we do not want to trigger builds on PRs.\\nEnable `Project settings` -> `Trusted`\\nEnable `Project Visibility` -> `Internal` unless you want to make it public.\\n\\n> We strictly recommend to use `Internal` visibility for your projects, because if you use `Public` visibility, your build logs will be public and if accidentally you will print some secret to console, it will be public (generally it happens when you debug something and print environment variables).\\n\\n![Woodpecker project settings](image-4.png)\\n\\n\\n### Generating GitHub acces token\\n\\nIf your repo is in GitHub organisation, you need first enable access to personal access tokens for your organisation (if not yet done):\\n\\n1. In the upper-right corner of GitHub, select your profile photo, then click `Your organizations`. \\n2. Next to the organization, click `Settings`.\\n3. In the left sidebar, under  Personal access tokens, click `Settings`.\\n4. Select `Allow access via fine-grained personal access tokens`\\n5. We recommend setting `Require administrator approval`\\n6. \\"Allow access via personal access tokens (classic)\\"\\n\\nNow go to your profile, click on `Settings` -> `Developer settings` -> `Personal access tokens` -> `Generate new token`\\n\\nFor permissions,\\n* Select `Contents`: `Read and Write`\\n* Select `Metadata`: `Read-only` (if not yet selected)\\n\\n\\nIn Woodpecker go to `Settings`, `Secrets`, `Add Secret`, put name name: `GITHUB_TOKEN` and paste your token:\\n\\n![Woodpecker Secrets](image.png)\\n\\nIn `Available at following events` select `Push`.\\n\\n\\n### Generating NPM token\\n\\nGo to your npmjs.com account, click on `Profile Avatar` -> `Access Tokens` -> `Generate New Token` -> `New Granular Access Token`.\\n\\nPackages and scopes Permissions: Read and Write.\\n\\nIn similar way to GitHub token, add it to Woodpecker as secret with name `NPM_TOKEN`\\n\\n\\n## Testing\\n\\nFor now we did not yet push anything to GitHub and did not publish anything to npm. \\n\\nLets do it now.\\n\\nJust push your first commit as:\\n\\n\\n```sh\\nfeat: initial commit\\n```\\n\\nThis will trigger semantic-release to do first release `v1.0.0`.\\n\\nNow change something is index.ts and push it as fix\\n\\n```sh\\nfix: fix greet function\\n```\\n\\nThis will trigger semantic-release to do release `v1.0.1`.\\n\\n\\nNow change something in `index.ts` and push it as feat\\n\\n```sh\\nfeat: add new function\\n```\\n\\nThis will trigger semantic-release to do release `v1.1.0` because we added new feature, not just fixed something.\\n\\n\\n### Next distribution channel\\n\\nNow we will show how to release to `next` channel.\\n\\n```sh\\ngit checkout -b next\\n```\\n\\nChange something and push it as fix\\n\\n```sh\\nfix: fix greet function in next\\n```\\n\\nCommit it and push:\\n\\n```sh\\ngit push --set-upstream origin next\\n```\\n\\nThis will trigger semantic-release to do release `v1.1.1-next.1`. Please not that it bumped patch version because we are in `next` channel.\\n\\nNow lets add feature to next\\n\\n```\\nfeat: add new feature in next\\n```\\n\\nIt will trigger release `v1.2.0-next.1` because we added new feature and minor version was bumped. Please not that next number started from 1 again.\\n\\nNoe lets merge `next` to `main` and push it:\\n\\n```\\ngit checkout main\\ngit merge next\\ngit push\\n```\\n\\nThis will trigger release `v1.2.0` because we merged `next` to `main` and it was a feature release.\\n\\n\\n## Slack notifications about releases\\n\\nSo now we have automatic releases with release notes on GitHub. \\nFor our internal team we use Slack and we want to get notifications about releases there.\\n\\n```sh\\nnpm i -D semantic-release-slack-bot\\n```\\n\\nInto \\"release\\" section of `package.json` add slack plugin:\\n\\n```\\n \\"plugins\\": [\\n      \\"@semantic-release/commit-analyzer\\",\\n      \\"@semantic-release/release-notes-generator\\",\\n      \\"@semantic-release/npm\\",\\n      \\"@semantic-release/github\\",\\n//diff-add\\n      [\\n//diff-add\\n        \\"semantic-release-slack-bot\\",\\n//diff-add\\n        {\\n//diff-add\\n          \\"notifyOnSuccess\\": true,\\n//diff-add\\n          \\"notifyOnFail\\": true,\\n//diff-add\\n          \\"slackIcon\\": \\":package:\\",\\n//diff-add\\n          \\"markdownReleaseNotes\\": true\\n//diff-add\\n        }\\n//diff-add\\n      ]\\n//diff-add\\n    ],\\n```\\n\\n\\nAlso create channel in Slack, click on channel name, go to `Integrations` -> `Add an App` -> `Incoming Webhooks` -> `Add to Slack` -> \\"Add Incoming Webhook to Workspace\\" -> \\"Add to Slack\\" -> \\"Copy Webhook URL\\"\\n\\nAdd it to Woodpecker as secret `SLACK_WEBHOOK` environment variable.\\n\\nAlso add this secterd to `.woodpecker.yml`:\\n\\n```yaml title=\\"deploy/.woodpecker.yml\\"\\n    secrets:\\n      - GITHUB_TOKEN\\n      - NPM_TOKEN\\n//diff-add\\n      - SLACK_WEBHOOK\\n```\\n\\n\\nThis will send notifications to Slack channel about succesfull releases when `npm run build` is done without errors:\\n\\n![Slack notifications about releases](image-5.png)\\n\\n\\n## Should I maintain CHANGELOG.md anymore?\\n\\n`semantic-release` has a plugin for generating not only GitHub release notes, but also CHANGELOG.md.\\n\\nSince previusly we used CHANGELOG.md I thought it would be good to have it in project. But once I entered [plugin page](https://github.com/semantic-release/changelog) I got a notice which [explained complexity](https://semantic-release.gitbook.io/semantic-release/support/faq#should-release-notes-be-committed-to-a-changelog.md-in-my-repository-during-a-release) added for this approach.\\n\\nSo we ended with a simple [link to GitHub releases](https://github.com/devforth/adminforth/blob/main/CHANGELOG.md)"},{"id":"backup-database-to-aws-glacier","metadata":{"permalink":"/blog/backup-database-to-aws-glacier","source":"@site/blog/2024-12-11-backup/index.md","title":"Backup database to AWS Glacier","description":"Every reliable system requires a backup strategy.","date":"2024-12-11T00:00:00.000Z","tags":[{"inline":false,"label":"AWS","permalink":"/blog/tags/aws","description":"Amazon Web Services (AWS) is a cloud computing platform that provides a wide range of services for building and deploying applications."},{"inline":false,"label":"Terraform","permalink":"/blog/tags/terraform","description":"Terraform is an open-source infrastructure as code software tool created by HashiCorp that enables users to define and provision data center infrastructure using a declarative configuration language."}],"readingTime":1.845,"hasTruncateMarker":false,"authors":[{"name":"Ivan Borshcho","title":"Maintainer of AdminForth","url":"https://github.com/ivictbor","imageURL":"https://avatars.githubusercontent.com/u/1838656?v=4","key":"ivanb","page":null}],"frontMatter":{"slug":"backup-database-to-aws-glacier","title":"Backup database to AWS Glacier","authors":"ivanb","tags":["aws","terraform"]},"unlisted":false,"prevItem":{"title":"Why manual releases and release notes is a chaos and how to fix it","permalink":"/blog/how-we-manage-versions"},"nextItem":{"title":"Deploy AdminForth to EC2 with terraform on CI","permalink":"/blog/compose-ec2-deployment-github-actions"}},"content":"Every reliable system requires a backup strategy. \\n\\nIf you have no own backup infrastructure, here can suggest a small docker container that will help you to backup your database to AWS Glacier.\\n\\nAs a base guide we will use a previous blog post about [deploying adminforth infrastructure](/blog/compose-ec2-deployment-github-actions).\\n\\n\\nFirst we need to allocate a new bucket in AWS S3 with modifying terraform configuration:\\n\\n```hcl title=\\"deploy/main.tf\\"\\nresource \\"aws_s3_bucket\\" \\"backup_bucket\\" {\\n  bucket = \\"${local.app_name}-backups\\"\\n}\\n\\nresource \\"aws_s3_bucket_lifecycle_configuration\\" \\"backup_bucket\\" {\\n  bucket = aws_s3_bucket.backup_bucket.bucket\\n\\n  rule {\\n    id     = \\"glacier-immediate\\"\\n    status = \\"Enabled\\"\\n\\n    transition {\\n      days          = 0\\n      storage_class = \\"GLACIER\\"\\n    }\\n  }\\n}\\n\\nresource \\"aws_s3_bucket_server_side_encryption_configuration\\" \\"backup_bucket\\" {\\n  bucket = aws_s3_bucket.backup_bucket.bucket\\n\\n  rule {\\n    apply_server_side_encryption_by_default {\\n      sse_algorithm = \\"AES256\\"\\n    }\\n  }\\n}\\n\\nresource \\"aws_iam_user\\" \\"backup_user\\" {\\n  name = \\"${local.app_name}-backup-user\\"\\n}\\n\\nresource \\"aws_iam_access_key\\" \\"backup_user_key\\" {\\n  user = aws_iam_user.backup_user.name\\n}\\n\\nresource \\"aws_iam_user_policy\\" \\"backup_user_policy\\" {\\n  name = \\"${local.app_name}-backup-policy\\"\\n  user = aws_iam_user.backup_user.name\\n\\n  policy = jsonencode({\\n    Version = \\"2012-10-17\\"\\n    Statement = [\\n      {\\n        Effect = \\"Allow\\"\\n        Action = [\\n          \\"s3:PutObject\\",\\n          \\"s3:GetObject\\",\\n          \\"s3:DeleteObject\\",\\n          \\"s3:ListBucket\\"\\n        ]\\n        Resource = [\\n          aws_s3_bucket.backup_bucket.arn,\\n          \\"${aws_s3_bucket.backup_bucket.arn}/*\\"\\n        ]\\n      }\\n    ]\\n  })\\n}\\n\\n```\\n\\nAlso add a section to main.tf to output the new bucket name and credentials:\\n\\n```hcl title=\\"deploy/main.tf\\"\\n      \\"docker system prune -f\\",\\n      # \\"docker buildx prune -f --filter \'type!=exec.cachemount\'\\",\\n      \\"cd /home/ubuntu/app/deploy\\",\\n//diff-add      \\n      \\"echo \'AWS_BACKUP_ACCESS_KEY=${aws_iam_access_key.backup_user_key.id}\' >> .env.live\\",\\n//diff-add\\n      \\"echo \'AWS_BACKUP_SECRET_KEY=${aws_iam_access_key.backup_user_key.secret}\' >> .env.live\\",\\n//diff-add\\n      \\"echo \'AWS_BACKUP_BUCKET=${aws_s3_bucket.backup_bucket.id}\' >> .env.live\\",\\n//diff-add\\n      \\"echo \'AWS_BACKUP_REGION=${local.aws_region}\' >> .env.live\\",\\n\\n      \\"docker compose -p app -f compose.yml --env-file ./.env.live up --build -d --quiet-pull\\"\\n    ]\\n```\\n\\n\\nAdd new service into compose file:\\n\\n```yaml title=\\"deploy/compose.yml\\"\\n\\n  database_glacierizer:\\n    image: devforth/docker-database-glacierizer:v1.7\\n\\n    environment:\\n      - PROJECT_NAME=MYAPP\\n      # do backup every day at 00:00\\n      - CRON=0 0 * * *  \\n\\n      - DATABASE_TYPE=PostgreSQL\\n      - DATABASE_HOST=db\\n      - DATABASE_NAME=adminforth\\n      - DATABASE_USER=admin\\n      - DATABASE_PASSWORD=${VAULT_POSTGRES_PASSWORD}\\n      - GLACIER_EXPIRE_AFTER=90\\n      - GLACIER_STORAGE_CLASS=flexible\\n      - GLACIER_BUCKET_NAME=${AWS_BACKUP_BUCKET}\\n\\n      - AWS_DEFAULT_REGION=${AWS_BACKUP_REGION}\\n      - AWS_ACCESS_KEY_ID=${AWS_BACKUP_ACCESS_KEY}\\n      - AWS_SECRET_ACCESS_KEY=${AWS_BACKUP_SECRET_KEY}\\n```\\n\\n\\n\\n## Pricing\\n\\nJust to give you row idea about pricing, here is a small calculation for case when you doing backup once per day (like in config)\\n* Compressed database backup has size of 50 MB always and not growing. (Compression is already done by glacierizer)\\n* Cost of glacier every month will be ~$0.80 after first 3 month, and will stay same every next month.  \\n* On first, second and third month cost will increase slowly from $0.00 to $0.80 per month."},{"id":"compose-ec2-deployment-github-actions","metadata":{"permalink":"/blog/compose-ec2-deployment-github-actions","source":"@site/blog/2024-11-14-compose-ec2-deployment-ci/index.md","title":"Deploy AdminForth to EC2 with terraform on CI","description":"Here is more advanced snippet to deploy AdminForth to Terraform.","date":"2024-11-14T00:00:00.000Z","tags":[{"inline":false,"label":"AWS","permalink":"/blog/tags/aws","description":"Amazon Web Services (AWS) is a cloud computing platform that provides a wide range of services for building and deploying applications."},{"inline":false,"label":"Terraform","permalink":"/blog/tags/terraform","description":"Terraform is an open-source infrastructure as code software tool created by HashiCorp that enables users to define and provision data center infrastructure using a declarative configuration language."},{"inline":false,"label":"GitHub Actions","permalink":"/blog/tags/github-actions","description":"GitHub Actions is a continuous integration and continuous deployment (CI/CD) service provided by GitHub that allows you to automate your software development workflows."}],"readingTime":7.53,"hasTruncateMarker":false,"authors":[{"name":"Ivan Borshcho","title":"Maintainer of AdminForth","url":"https://github.com/ivictbor","imageURL":"https://avatars.githubusercontent.com/u/1838656?v=4","key":"ivanb","page":null}],"frontMatter":{"slug":"compose-ec2-deployment-github-actions","title":"Deploy AdminForth to EC2 with terraform on CI","authors":"ivanb","tags":["aws","terraform","github-actions"]},"unlisted":false,"prevItem":{"title":"Backup database to AWS Glacier","permalink":"/blog/backup-database-to-aws-glacier"},"nextItem":{"title":"Deploy AdminForth to EC2 with terraform (without CI)","permalink":"/blog/compose-ec2-deployment"}},"content":"Here is more advanced snippet to deploy AdminForth to Terraform.\\n\\nHere Terraform state will be stored in the cloud, so you can run this deployment from any machine including stateless CI/CD.\\n\\nWe will use GitHub Actions as CI/CD, but you can use any other CI/CD, for example self-hosted free WoodpeckerCI.\\n\\nAssume you have your AdminForth project in `myadmin`.\\n\\n\\n## Step 1 - Dockerfile\\n\\nCreate file `Dockerfile` in `myadmin`:\\n\\n```Dockerfile title=\\"./myadmin/Dockerfile\\"\\n# use the same node version which you used during dev\\nFROM node:20-alpine\\nWORKDIR /code/\\nADD package.json package-lock.json /code/\\nRUN npm ci  \\nADD . /code/\\nRUN --mount=type=cache,target=/tmp npx tsx bundleNow.ts\\nCMD [\\"npm\\", \\"run\\", \\"startLive\\"]\\n```\\n\\n\\n## Step 2 - compose.yml\\n\\ncreate folder `deploy` and create file `compose.yml` inside:\\n\\n```yml title=\\"deploy/compose.yml\\"\\n\\nservices:\\n  traefik:\\n    image: \\"traefik:v2.5\\"\\n    command:\\n      - \\"--api.insecure=true\\"\\n      - \\"--providers.docker=true\\"\\n      - \\"--entrypoints.web.address=:80\\"\\n    ports:\\n      - \\"80:80\\"\\n    volumes:\\n      - \\"/var/run/docker.sock:/var/run/docker.sock:ro\\"\\n\\n  myadmin:\\n    build: ./myadmin\\n    restart: always\\n    env_file:\\n      - ./myadmin/.env\\n    volumes:\\n      - myadmin-db:/code/db\\n    labels:\\n      - \\"traefik.enable=true\\"\\n      - \\"traefik.http.routers.myadmin.rule=PathPrefix(`/`)\\"\\n      - \\"traefik.http.services.myadmin.loadbalancer.server.port=3500\\"\\n      - \\"traefik.http.routers.myadmin.priority=2\\"\\n\\nvolumes:\\n  myadmin-db:\\n```\\n\\n## Step 3 - create a SSH keypair\\n\\nMake sure you are in `deploy` folder, run next command here:\\n\\n```bash title=\\"deploy\\"\\nmkdir .keys && ssh-keygen -f .keys/id_rsa -N \\"\\"\\n```\\n\\nNow it should create `deploy/.keys/id_rsa` and `deploy/.keys/id_rsa.pub` files with your SSH keypair. Terraform script will put the public key to the EC2 instance and will use private key to connect to the instance. Also you will be able to use it to connect to the instance manually.\\n\\n## Step 4 - .gitignore file\\n\\nCreate `deploy/.gitignore` file with next content:\\n\\n```bash\\n.terraform/\\n.keys/\\n*.tfstate\\n*.tfstate.*\\n*.tfvars\\ntfplan\\n```\\n\\n## Step 5 - Main terraform file main.tf\\n\\n\\n\\nFirst of all install Terraform as described here [terraform installation](https://developer.hashicorp.com/terraform/install#linux).\\n\\n\\nCreate file `main.tf` in `deploy` folder:\\n\\n```hcl title=\\"deploy/main.tf\\"\\n\\nlocals {\\n  app_name = \\"<your_app_name>\\"\\n  aws_region = \\"eu-central-1\\"\\n}\\n\\n\\nprovider \\"aws\\" {\\n  region = local.aws_region\\n  profile = \\"myaws\\"\\n}\\n\\ndata \\"aws_ami\\" \\"ubuntu_linux\\" {\\n  most_recent = true\\n  owners      = [\\"amazon\\"]\\n\\n  filter {\\n    name   = \\"name\\"\\n    values = [\\"ubuntu/images/hvm-ssd-gp3/ubuntu-noble-24.04-amd64-server-*\\"]\\n  }\\n}\\n\\ndata \\"aws_vpc\\" \\"default\\" {\\n  default = true\\n}\\n\\n\\nresource \\"aws_eip\\" \\"eip\\" {\\n domain = \\"vpc\\"\\n}\\nresource \\"aws_eip_association\\" \\"eip_assoc\\" {\\n instance_id   = aws_instance.app_instance.id\\n allocation_id = aws_eip.eip.id\\n}\\n\\ndata \\"aws_subnet\\" \\"default_subnet\\" {\\n  filter {\\n    name   = \\"vpc-id\\"\\n    values = [data.aws_vpc.default.id]\\n  }\\n\\n  filter {\\n    name   = \\"default-for-az\\"\\n    values = [\\"true\\"]\\n  }\\n\\n  filter {\\n    name   = \\"availability-zone\\"\\n    values = [\\"${local.aws_region}a\\"]\\n  }\\n}\\n\\nresource \\"aws_security_group\\" \\"instance_sg\\" {\\n  name   = \\"${local.app_name}-instance-sg\\"\\n  vpc_id = data.aws_vpc.default.id\\n\\n  ingress {\\n    description = \\"Allow HTTP\\"\\n    from_port   = 80\\n    to_port     = 80\\n    protocol    = \\"tcp\\"\\n    cidr_blocks = [\\"0.0.0.0/0\\"]\\n  }\\n\\n  # SSH\\n  ingress {\\n    description = \\"Allow SSH\\"\\n    from_port   = 22\\n    to_port     = 22\\n    protocol    = \\"tcp\\"\\n    cidr_blocks = [\\"0.0.0.0/0\\"]\\n  }\\n\\n  egress {\\n    description = \\"Allow all outbound traffic\\"\\n    from_port   = 0\\n    to_port     = 0\\n    protocol    = \\"-1\\"\\n    cidr_blocks = [\\"0.0.0.0/0\\"]\\n  }\\n}\\n\\nresource \\"aws_key_pair\\" \\"app_deployer\\" {\\n  key_name   = \\"terraform-deploy_${local.app_name}-key\\"\\n  public_key = file(\\"./.keys/id_rsa.pub\\") # Path to your public SSH key\\n}\\n\\nresource \\"aws_instance\\" \\"app_instance\\" {\\n  ami                    = data.aws_ami.ubuntu_linux.id\\n  instance_type          = \\"t3a.small\\"\\n  subnet_id              = data.aws_subnet.default_subnet.id\\n  vpc_security_group_ids = [aws_security_group.instance_sg.id]\\n  key_name               = aws_key_pair.app_deployer.key_name\\n\\n  # prevent accidental termination of ec2 instance and data loss\\n  # if you will need to recreate the instance still (not sure why it can be?), you will need to remove this block manually by next command:\\n  # > terraform taint aws_instance.app_instance\\n  lifecycle {\\n    prevent_destroy = true\\n    ignore_changes = [ami]\\n  }\\n\\n  root_block_device {\\n    volume_size = 20 // Size in GB for root partition\\n    volume_type = \\"gp2\\"\\n\\n    # Even if the instance is terminated, the volume will not be deleted, delete it manually if needed\\n    delete_on_termination = false\\n  }\\n\\n  user_data = <<-EOF\\n    #!/bin/bash\\n    sudo apt-get update\\n    sudo apt-get install ca-certificates curl\\n    sudo install -m 0755 -d /etc/apt/keyrings\\n    sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\\n    sudo chmod a+r /etc/apt/keyrings/docker.asc\\n\\n    # Add the repository to Apt sources:\\n    echo \\\\\\n      \\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\\\\n      $(. /etc/os-release && echo \\"$VERSION_CODENAME\\") stable\\" | \\\\\\n      sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\\n    sudo apt-get update\\n\\n    sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\\n\\n    systemctl start docker\\n    systemctl enable docker\\n    usermod -a -G docker ubuntu\\n  EOF\\n\\n  tags = {\\n    Name = \\"${local.app_name}-instance\\"\\n  }\\n}\\n\\nresource \\"null_resource\\" \\"sync_files_and_run\\" {\\n  # Use rsync to exclude node_modules, .git, db\\n  provisioner \\"local-exec\\" {\\n    # heredoc syntax\\n    # remove files that where deleted on the source\\n    command = <<-EOF\\n    #  -o StrictHostKeyChecking=no\\n    rsync -t -av -e \\"ssh -i ./.keys/id_rsa -o StrictHostKeyChecking=no\\" \\\\\\n      --delete \\\\\\n      --exclude \'node_modules\' \\\\\\n      --exclude \'.git\' \\\\\\n      --exclude \'.terraform\' \\\\\\n      --exclude \'terraform*\' \\\\\\n      --exclude \'tfplan\' \\\\\\n      --exclude \'.keys\' \\\\\\n      --exclude \'.vscode\' \\\\\\n      --exclude \'.env\' \\\\\\n      --exclude \'db\' \\\\\\n      ../ ubuntu@${aws_eip_association.eip_assoc.public_ip}:/home/ubuntu/app/\\n    EOF\\n  }\\n\\n  # Run docker compose after files have been copied\\n  provisioner \\"remote-exec\\" {\\n    inline = [\\n      # fail bash specially and intentionally to stop the script on error\\n      \\"bash -c \'while ! command -v docker &> /dev/null; do echo \\\\\\"Waiting for Docker to be installed...\\\\\\"; sleep 1; done\'\\",\\n      \\"bash -c \'while ! docker info &> /dev/null; do echo \\\\\\"Waiting for Docker to start...\\\\\\"; sleep 1; done\'\\",\\n      \\n      # please note that prune might destroy build cache and make build slower, however it releases disk space\\n      \\"docker system prune -f\\",\\n      # \\"docker buildx prune -f --filter \'type!=exec.cachemount\'\\",\\n      \\"cd /home/ubuntu/app/deploy\\",\\n      # COMPOSE_FORCE_NO_TTY is needed to run docker compose in non-interactive mode and prevent stdout mess up\\n      \\"COMPOSE_FORCE_NO_TTY=1 docker compose -p app -f compose.yml up --build -d\\"\\n    ]\\n\\n    connection {\\n      type        = \\"ssh\\"\\n      user        = \\"ubuntu\\"\\n      private_key = file(\\"./.keys/id_rsa\\")\\n      host        = aws_eip_association.eip_assoc.public_ip\\n    }\\n  }\\n\\n  # Ensure the resource is triggered every time based on timestamp or file hash\\n  triggers = {\\n    always_run = timestamp()\\n  }\\n\\n  depends_on = [aws_instance.app_instance, aws_eip_association.eip_assoc]\\n}\\n\\n\\noutput \\"instance_public_ip\\" {\\n  value = aws_eip_association.eip_assoc.public_ip\\n}\\n\\n\\n######### This scetion is for tf state storage ##############\\n\\n# S3 bucket for storing Terraform state\\nresource \\"aws_s3_bucket\\" \\"terraform_state\\" {\\n  bucket = \\"${local.app_name}-terraform-state\\"\\n}\\n\\nresource \\"aws_s3_bucket_lifecycle_configuration\\" \\"terraform_state\\" {\\n  bucket = aws_s3_bucket.terraform_state.bucket\\n\\n  rule {\\n    status = \\"Enabled\\"\\n    id = \\"Keep only the latest version of the state file\\"\\n\\n    noncurrent_version_expiration {\\n      noncurrent_days = 30\\n    }\\n  }\\n}\\n\\nresource \\"aws_s3_bucket_versioning\\" \\"terraform_state\\" {\\n  bucket = aws_s3_bucket.terraform_state.bucket\\n\\n  versioning_configuration {\\n    status = \\"Enabled\\"\\n  }\\n}\\n\\nresource \\"aws_s3_bucket_server_side_encryption_configuration\\" \\"terraform_state\\" {\\n  bucket = aws_s3_bucket.terraform_state.bucket\\n\\n  rule {\\n    apply_server_side_encryption_by_default {\\n      sse_algorithm     = \\"AES256\\"\\n    }\\n  }\\n}\\n\\n\\n```\\n\\n> \ud83d\udc46 Replace `<your_app_name>` with your app name (no spaces, only underscores or letters)\\n\\n### Step 5.1 - Configure AWS Profile\\n\\nOpen or create file ~/.aws/credentials and add (if not already there):\\n\\n```ini\\n[myaws]\\naws_access_key_id = <your_access_key>\\naws_secret_access_key = <your_secret_key>\\n```\\n\\n### Step 5.2 - Run deployment\\n\\nTo run the deployment first time, you need to run:\\n\\n```bash\\nterraform init\\n```\\n\\nNow run deployement:\\n\\n```bash\\nterraform apply -auto-approve\\n```\\n\\n## Step 6 - Migrate state to the cloud\\n\\nFirst deployment had to create S3 bucket and DynamoDB table for storing Terraform state. Now we need to migrate the state to the cloud.\\n\\nAdd to the end of `main.tf`:\\n\\n```hcl title=\\"main.tf\\"\\n\\n# Configure the backend to use the S3 bucket and DynamoDB table\\nterraform {\\n backend \\"s3\\" {\\n   bucket         = \\"<your_app_name>-terraform-state\\"\\n   key            = \\"state.tfstate\\"  # Define a specific path for the state file\\n   region         = \\"eu-central-1\\"\\n   profile        = \\"myaws\\"\\n   dynamodb_table = \\"<your_app_name>-terraform-lock-table\\"\\n   use_lockfile   = true\\n }\\n}\\n```\\n\\n> \ud83d\udc46 Replace `<your_app_name>` with your app name (no spaces, only underscores or letters). \\n> Unfortunately we can\'t use variables, HashiCorp thinks it is too dangerous \ud83d\ude25\\n\\n\\nNow run:\\n\\n```bash\\nterraform init -migrate-state\\n```\\n\\nNow run test deployment:\\n\\n```bash\\nterraform apply -auto-approve\\n```\\n\\nNow you can delete local `terraform.tfstate` file and `terraform.tfstate.backup` file as they are in the cloud now.\\n\\n\\n## Step 7 - CI/CD - Github Actions\\n\\nCreate file `.github/workflows/deploy.yml`:\\n\\n```yml title=\\".github/workflows/deploy.yml\\"\\nname: Deploy \\nrun-name: ${{ github.actor }} builds app \ud83d\ude80\\non: [push]\\njobs:\\n  Explore-GitHub-Actions:\\n    runs-on: ubuntu-latest\\n    steps:\\n      - run: echo \\"\ud83c\udf89 The job was automatically triggered by a ${{ github.event_name }} event.\\"\\n      - run: echo \\"\ud83d\udc27 This job is now running on a ${{ runner.os }} server\\"\\n      - run: echo \\"\ud83d\udd0e The name of your branch is ${{ github.ref }}\\"\\n      - name: Check out repository code\\n        uses: actions/checkout@v4\\n      - name: Set up Terraform\\n        uses: hashicorp/setup-terraform@v2\\n        with:\\n          terraform_version: 1.4.6  \\n      - run: echo \\"\ud83d\udca1 The ${{ github.repository }} repository has been cloned to the runner.\\"\\n      - name: Start building\\n        env:\\n          VAULT_AWS_ACCESS_KEY_ID: ${{ secrets.VAULT_AWS_ACCESS_KEY_ID }}\\n          VAULT_AWS_SECRET_ACCESS_KEY: ${{ secrets.VAULT_AWS_SECRET_ACCESS_KEY }}\\n          VAULT_SSH_PRIVATE_KEY: ${{ secrets.VAULT_SSH_PRIVATE_KEY }}\\n          VAULT_SSH_PUBLIC_KEY: ${{ secrets.VAULT_SSH_PUBLIC_KEY }}\\n        run: |\\n          /bin/sh -x deploy/deploy.sh\\n          \\n      - run: echo \\"\ud83c\udf4f This job\'s status is ${{ job.status }}.\\"\\n```\\n\\n### Step 7.1 - Create deploy script\\n\\nNow create file `deploy/deploy.sh`:\\n\\n```bash title=\\"deploy/deploy.sh\\"\\n\\n# cd to dir of script\\ncd \\"$(dirname \\"$0\\")\\"\\n\\nmkdir -p ~/.aws ./.keys\\n\\ncat <<EOF > ~/.aws/credentials\\n[myaws]\\naws_access_key_id=$VAULT_AWS_ACCESS_KEY_ID\\naws_secret_access_key=$VAULT_AWS_SECRET_ACCESS_KEY\\nEOF\\n\\ncat <<EOF > ./.keys/id_rsa\\n$VAULT_SSH_PRIVATE_KEY\\nEOF\\n\\ncat <<EOF > ./.keys/id_rsa.pub\\n$VAULT_SSH_PUBLIC_KEY\\nEOF\\n\\nchmod 600 ./.keys/id_rsa*\\n\\n# force Terraform to reinitialize the backend without migrating the state.\\nterraform init -reconfigure\\nterraform plan -out=tfplan\\nterraform apply tfplan\\n```\\n\\n### Step 7.2 - Add secrets to GitHub\\n\\nGo to your GitHub repository, then `Settings` -> `Secrets` -> `New repository secret` and add:\\n\\n- `VAULT_AWS_ACCESS_KEY_ID` - your AWS access key\\n- `VAULT_AWS_SECRET_ACCESS_KEY` - your AWS secret key\\n- `VAULT_SSH_PRIVATE_KEY` - make `cat ~/.ssh/id_rsa` and paste to GitHub secrets\\n- `VAULT_SSH_PUBLIC_KEY` - make `cat ~/.ssh/id_rsa.pub` and paste to GitHub secrets\\n\\n\\nNow you can push your changes to GitHub and see how it will be deployed automatically."},{"id":"compose-ec2-deployment","metadata":{"permalink":"/blog/compose-ec2-deployment","source":"@site/blog/2024-10-31-compose-ec2-deployment/index.md","title":"Deploy AdminForth to EC2 with terraform (without CI)","description":"Here is a row snippet to deploy AdminForth to Terraform.","date":"2024-10-31T00:00:00.000Z","tags":[{"inline":false,"label":"AWS","permalink":"/blog/tags/aws","description":"Amazon Web Services (AWS) is a cloud computing platform that provides a wide range of services for building and deploying applications."},{"inline":false,"label":"Terraform","permalink":"/blog/tags/terraform","description":"Terraform is an open-source infrastructure as code software tool created by HashiCorp that enables users to define and provision data center infrastructure using a declarative configuration language."}],"readingTime":3.485,"hasTruncateMarker":false,"authors":[{"name":"Ivan Borshcho","title":"Maintainer of AdminForth","url":"https://github.com/ivictbor","imageURL":"https://avatars.githubusercontent.com/u/1838656?v=4","key":"ivanb","page":null}],"frontMatter":{"slug":"compose-ec2-deployment","title":"Deploy AdminForth to EC2 with terraform (without CI)","authors":"ivanb","tags":["aws","terraform"]},"unlisted":false,"prevItem":{"title":"Deploy AdminForth to EC2 with terraform on CI","permalink":"/blog/compose-ec2-deployment-github-actions"},"nextItem":{"title":"Build AI-Assisted blog with AdminForth and Nuxt in 20 minutes","permalink":"/blog/ai-blog"}},"content":"Here is a row snippet to deploy AdminForth to Terraform.\\n\\nAssume you have your AdminForth project in `myadmin`.\\n\\nCreate file `Dockerfile` in `myadmin`:\\n\\n```Dockerfile title=\\"./myadmin/Dockerfile\\"\\n# use the same node version which you used during dev\\nFROM node:20-alpine\\nWORKDIR /code/\\nADD package.json package-lock.json /code/\\nRUN npm ci  \\nADD . /code/\\nRUN --mount=type=cache,target=/tmp npx tsx bundleNow.ts\\nCMD [\\"npm\\", \\"run\\", \\"startLive\\"]\\n```\\n\\n\\nCreate file `compose.yml`:\\n\\n```yml title=\\"compose.yml\\"\\n\\nservices:\\n  traefik:\\n    image: \\"traefik:v2.5\\"\\n    command:\\n      - \\"--api.insecure=true\\"\\n      - \\"--providers.docker=true\\"\\n      - \\"--entrypoints.web.address=:80\\"\\n    ports:\\n      - \\"80:80\\"\\n    volumes:\\n      - \\"/var/run/docker.sock:/var/run/docker.sock:ro\\"\\n\\n  myadmin:\\n    build: ./myadmin\\n    restart: always\\n    env_file:\\n      - ./myadmin/.env\\n    volumes:\\n      - myadmin-db:/code/db\\n    labels:\\n      - \\"traefik.enable=true\\"\\n      - \\"traefik.http.routers.myadmin.rule=PathPrefix(`/`)\\"\\n      - \\"traefik.http.services.myadmin.loadbalancer.server.port=3500\\"\\n      - \\"traefik.http.routers.myadmin.priority=2\\"\\n\\nvolumes:\\n  myadmin-db:\\n```\\n\\n\\n\\nCreate file `main.tf`:\\n\\n```hcl title=\\"main.tf\\"\\n\\nprovider \\"aws\\" {\\n  region = \\"eu-central-1\\"\\n  profile = \\"myaws\\"\\n}\\n\\ndata \\"aws_ami\\" \\"ubuntu_linux\\" {\\n  most_recent = true\\n  owners      = [\\"amazon\\"]\\n\\n  filter {\\n    name   = \\"name\\"\\n    values = [\\"ubuntu/images/hvm-ssd-gp3/ubuntu-noble-24.04-amd64-server-*\\"]\\n  }\\n}\\n\\ndata \\"aws_vpc\\" \\"default\\" {\\n  default = true\\n}\\n\\nresource \\"aws_eip\\" \\"eip\\" {\\n vpc = true\\n}\\nresource \\"aws_eip_association\\" \\"eip_assoc\\" {\\n instance_id   = aws_instance.myadmin_instance.id\\n allocation_id = aws_eip.eip.id\\n}\\n\\ndata \\"aws_subnet\\" \\"default_subnet\\" {\\n  filter {\\n    name   = \\"vpc-id\\"\\n    values = [data.aws_vpc.default.id]\\n  }\\n\\n  filter {\\n    name   = \\"default-for-az\\"\\n    values = [\\"true\\"]\\n  }\\n\\n  filter {\\n    name   = \\"availability-zone\\"\\n    values = [\\"eu-central-1a\\"]\\n  }\\n}\\n\\n\\nresource \\"aws_security_group\\" \\"instance_sg\\" {\\n  name   = \\"myadmin-instance-sg\\"\\n  vpc_id = data.aws_vpc.default.id\\n\\n  ingress {\\n    description = \\"Allow HTTP\\"\\n    from_port   = 80\\n    to_port     = 80\\n    protocol    = \\"tcp\\"\\n    cidr_blocks = [\\"0.0.0.0/0\\"]\\n  }\\n\\n  # SSH\\n  ingress {\\n    description = \\"Allow SSH\\"\\n    from_port   = 22\\n    to_port     = 22\\n    protocol    = \\"tcp\\"\\n    cidr_blocks = [\\"0.0.0.0/0\\"]\\n  }\\n\\n  egress {\\n    description = \\"Allow all outbound traffic\\"\\n    from_port   = 0\\n    to_port     = 0\\n    protocol    = \\"-1\\"\\n    cidr_blocks = [\\"0.0.0.0/0\\"]\\n  }\\n}\\n\\nresource \\"aws_key_pair\\" \\"myadmin_deploy_key\\" {\\n  key_name   = \\"terraform-myadmin_deploy_key-key\\"\\n  public_key = file(\\"~/.ssh/id_rsa.pub\\") # Path to your public SSH key\\n}\\n\\n\\nresource \\"aws_instance\\" \\"myadmin_instance\\" {\\n  ami                    = data.aws_ami.ubuntu_linux.id\\n  instance_type          = \\"t3a.small\\"\\n  subnet_id              = data.aws_subnet.default_subnet.id\\n  vpc_security_group_ids = [aws_security_group.instance_sg.id]\\n  key_name               = aws_key_pair.myadmin_deploy_key.key_name\\n\\n  # prevent accidental termination of ec2 instance and data loss\\n  # if you will need to recreate the instance still (not sure why it can be?), you will need to remove this block manually by next command:\\n  # > terraform taint aws_instance.app_instance\\n  lifecycle {\\n    prevent_destroy = true\\n    ignore_changes = [ami]\\n  }\\n\\n\\n  root_block_device {\\n    volume_size = 20 // Size in GB for root partition\\n    volume_type = \\"gp2\\"\\n\\n    # Even if the instance is terminated, the volume will not be deleted, delete it manually if needed\\n    delete_on_termination = false\\n  }\\n\\n  user_data = <<-EOF\\n    #!/bin/bash\\n    sudo apt-get update\\n    sudo apt-get install ca-certificates curl\\n    sudo install -m 0755 -d /etc/apt/keyrings\\n    sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\\n    sudo chmod a+r /etc/apt/keyrings/docker.asc\\n\\n    # Add the repository to Apt sources:\\n    echo \\\\\\n      \\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\\\\n      $(. /etc/os-release && echo \\"$VERSION_CODENAME\\") stable\\" | \\\\\\n      sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\\n    sudo apt-get update\\n\\n    sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\\n\\n    systemctl start docker\\n    systemctl enable docker\\n    usermod -a -G docker ubuntu\\n  EOF\\n\\n  tags = {\\n    Name = \\"myadmin-instance\\"\\n  }\\n}\\n\\nresource \\"null_resource\\" \\"sync_files_and_run\\" {\\n  # Use rsync to exclude node_modules, .git, db\\n  provisioner \\"local-exec\\" {\\n    # heredoc syntax\\n    command = <<-EOF\\n    rsync -t -av \\\\\\n      --delete \\\\\\n      --exclude \'node_modules\' \\\\\\n      --exclude \'.git\' \\\\\\n      --exclude \'.terraform\' \\\\\\n      --exclude \'terraform*\' \\\\\\n      --exclude \'.vscode\' \\\\\\n      --exclude \'db\' \\\\\\n      ./ ubuntu@${aws_eip_association.eip_assoc.public_ip}:/home/ubuntu/app/\\n    EOF\\n    \\n  }\\n\\n  # Run docker compose after files have been copied\\n  provisioner \\"remote-exec\\" {\\n    inline = [\\n      \\"bash -c \'while ! command -v docker &> /dev/null; do echo \\\\\\"Waiting for Docker to be installed...\\\\\\"; sleep 1; done\'\\",\\n      \\"bash -c \'while ! docker info &> /dev/null; do echo \\\\\\"Waiting for Docker to start...\\\\\\"; sleep 1; done\'\\",\\n      # -a would destroy cache\\n      \\"docker system prune -f\\",\\n      \\"cd /home/ubuntu/app/\\",\\n      # COMPOSE_FORCE_NO_TTY is needed to run docker compose in non-interactive mode and prevent stdout mess up\\n      \\"COMPOSE_FORCE_NO_TTY=1 docker compose -f compose.yml up --build -d\\"\\n    ]\\n\\n    connection {\\n      type        = \\"ssh\\"\\n      user        = \\"ubuntu\\"\\n      private_key = file(\\"~/.ssh/id_rsa\\")\\n      host        = aws_eip_association.eip_assoc.public_ip\\n    }\\n  }\\n\\n  # Ensure the resource is triggered every time based on timestamp or file hash\\n  triggers = {\\n    always_run = timestamp()\\n  }\\n\\n  depends_on = [aws_instance.myadmin_instance, aws_eip_association.eip_assoc]\\n}\\n\\n\\noutput \\"instance_public_ip\\" {\\n  value = aws_eip_association.eip_assoc.public_ip\\n}\\n```\\n\\n\\nTo run the deployment first time, you need to run:\\n\\n```bash\\nterraform init\\n```\\n\\nThen with any change in code:\\n\\n```bash\\nterraform apply -auto-approve\\n```"},{"id":"ai-blog","metadata":{"permalink":"/blog/ai-blog","source":"@site/blog/2024-10-01-ai-blog/index.md","title":"Build AI-Assisted blog with AdminForth and Nuxt in 20 minutes","description":"Many developers today are using copilots to write code faster and relax their minds from a routine tasks.","date":"2024-10-01T00:00:00.000Z","tags":[{"inline":false,"label":"Nuxt.js","permalink":"/blog/tags/nuxt","description":"Nuxt.js is a free and open-source web application framework based on Vue.js, Node.js, Webpack, and Babel.js."},{"inline":false,"label":"ChatGPT","permalink":"/blog/tags/chatgpt","description":"ChatGPT is a conversational AI model that can generate human-like responses to text inputs."}],"readingTime":18.48,"hasTruncateMarker":false,"authors":[{"name":"Ivan Borshcho","title":"Maintainer of AdminForth","url":"https://github.com/ivictbor","imageURL":"https://avatars.githubusercontent.com/u/1838656?v=4","key":"ivanb","page":null}],"frontMatter":{"slug":"ai-blog","title":"Build AI-Assisted blog with AdminForth and Nuxt in 20 minutes","authors":"ivanb","tags":["nuxt","chatgpt"]},"unlisted":false,"prevItem":{"title":"Deploy AdminForth to EC2 with terraform (without CI)","permalink":"/blog/compose-ec2-deployment"},"nextItem":{"title":"Chat-GPT plugin to co-write texts and strings","permalink":"/blog/chatgpt-plugin"}},"content":"Many developers today are using copilots to write code faster and relax their minds from a routine tasks.\\n\\nBut what about writing plain text? For example blogs and micro-blogs: sometimes you want to share your progress but you are lazy for typing. Then you can give a try to AI-assisted blogging. Our Open-Source AdminForth framework has couple of new AI-capable plugins to write text and generate images.\\n\\n![alt text](nuxtBlog.gif)\\n\\n\\nFor AI plugins are backed by OpenAI API, but their architecture allows to be easily extended for other AI providers once OpenAI competitors will reach the same or better level of quality.\\n\\nHere we will suggest you simple as 1-2-3 steps to build and host a blog with AI assistant which will help you to write posts.\\n\\nOur tech stack will include:\\n\\n- [Nuxt.js](https://nuxt.com/) - SEO-friendly page rendering framework\\n- [AdminForth](https://adminforth.dev/) - Admin panel framework for creating posts\\n- [AdminForth RichEditor plugin](https://adminforth.dev/docs/tutorial/Plugins/RichEditor/) - WYSIWYG editor with AI assistant in Copilot style\\n- Node and typescript\\n- Prisma for migrations\\n- SQLite for database, though you can easily switch it to Postgres or MongoDB\\n\\n## Prerequirements\\n\\nWe will use Node v20, if you not have it installed, we recommend [NVM](https://github.com/nvm-sh/nvm?tab=readme-ov-file#install--update-script)\\n\\n```bash\\nnvm install 20\\nnvm alias default 20\\nnvm use 20\\n```\\n\\n## Step 1: Create a new AdminForth project\\n\\n```bash\\nmkdir ai-blog\\ncd ai-blog\\nnpm init -y\\nnpm i adminforth @adminforth/upload @adminforth/rich-editor @adminforth/chat-gpt \\\\\\n express slugify http-proxy @types/express typescript tsx @types/node -D\\nnpx --yes tsc --init --module NodeNext --target ESNext\\n```\\n\\n## Step 2: Prepare environment\\n\\n### OpenAI\\n\\nTo allocate OpenAI API key, go to https://platform.openai.com/, open Dashboard -> API keys -> Create new secret key.\\n\\n### S3\\n\\n1. Go to https://aws.amazon.com and login.\\n2. Go to Services -> S3 and create a bucket. Put in bucket name e.g. `my-ai-blog-bucket`. \\nFirst of all go to your bucket settings, Permissions, scroll down to Block public access (bucket settings for this bucket) and uncheck all checkboxes.\\nGo to bucket settings, Permissions, Object ownership and select \\"ACLs Enabled\\" and \\"Bucket owner preferred\\" radio buttons.\\n3. Go to bucket settings, Permissions, scroll down to Cross-origin resource sharing (CORS) and put in the following configuration:\\n\\n```json\\n[\\n    {\\n        \\"AllowedHeaders\\": [\\n            \\"*\\"\\n        ],\\n        \\"AllowedMethods\\": [\\n            \\"PUT\\"\\n        ],\\n        \\"AllowedOrigins\\": [\\n            \\"http://localhost:3500\\"\\n        ],\\n        \\"ExposeHeaders\\": []\\n    }\\n]\\n```\\n\\n> \u261d\ufe0f In AllowedOrigins add all your domains. For example if you will serve blog and admin on `https://blog.example.com/` you should add \\n> `\\"https://blog.example.com\\"` to AllowedOrigins:\\n>\\n> ```json\\n> [\\n>      \\"https://blog.example.com\\",\\n>      \\"http://localhost:3500\\"\\n> ]\\n> ```\\n> Every character matters, so don\'t forget to add `http://` or `https://` and don\'t add slashes at the end of the domain.\\n\\n4. Go to Services -> IAM and create a new user. Put in user name e.g. `my-ai-blog-bucket`.\\n5. Attach existing policies directly -> `AmazonS3FullAccess`. Go to your user -> `Add permissions` -> `Attach policies directly` -> `AmazonS3FullAccess`\\n6. Go to Security credentials and create a new access key. Save `Access key ID` and `Secret access key`.\\n\\n\\n### Create .env file in project directory\\n\\nCreate `.env` file with the following content:\\n\\n```bash title=\\".env\\"\\nDATABASE_URL=file:./db/db.sqlite\\nADMINFORTH_SECRET=<some random string>\\nOPENAI_API_KEY=...\\nAWS_ACCESS_KEY_ID=your_access_key_id\\nAWS_SECRET_ACCESS_KEY=your_secret_access_key\\nAWS_S3_BUCKET=my-ai-blog-bucket\\nAWS_S3_REGION=us-east-1\\n```\\n\\n\\n## Step 3: Initialize database\\n\\nCreate `./schema.prisma` and put next content there:\\n\\n\\n```yaml title=\\"./schema.prisma\\" \\ngenerator client {\\n  provider = \\"prisma-client-js\\"\\n}\\n\\ndatasource db {\\n  provider = \\"sqlite\\"\\n  url      = env(\\"DATABASE_URL\\")\\n}\\n\\nmodel User {\\n  id           String     @id\\n  createdAt    DateTime \\n  email        String   @unique\\n  avatar       String?\\n  publicName   String?\\n  passwordHash String\\n  posts        Post[]\\n}\\n\\nmodel Post {\\n  id          String     @id\\n  createdAt   DateTime \\n  title       String\\n  slug        String\\n  picture     String?\\n  content     String\\n  published   Boolean  \\n  author      User?    @relation(fields: [authorId], references: [id])\\n  authorId    String?\\n  contentImages ContentImage[]\\n}\\n\\nmodel ContentImage {\\n  id         String     @id\\n  createdAt  DateTime \\n  img        String\\n  postId     String\\n  resourceId String\\n  post       Post      @relation(fields: [postId], references: [id])\\n}\\n```\\n\\nCreate database using `prisma migrate`:\\n\\n```bash\\nnpx -y prisma migrate dev --name init\\n```\\n\\n> in future if you will need to update schema, you can run `npx prisma migrate dev --name <name>` where `<name>` is a name of migration.\\n\\n## Step 4: Setting up AdminForth\\n\\n\\nOpen `package.json`, set `type` to `module` and add `start` script:\\n\\n```json title=\\"./package.json\\"\\n{\\n  ...\\n//diff-add\\n  \\"type\\": \\"module\\",\\n  \\"scripts\\": {\\n    ...\\n//diff-add\\n    \\"start\\": \\"NODE_ENV=development tsx watch --env-file=.env index.ts\\",\\n//diff-add\\n    \\"startLive\\": \\"NODE_ENV=production APP_PORT=80 tsx index.ts\\"\\n  },\\n}\\n```\\n\\nCreate `index.ts` file in root directory with following content:\\n\\n```ts title=\\"./index.ts\\"\\nimport express from \'express\';\\nimport AdminForth, { Filters, Sorts } from \'adminforth\';\\nimport userResource from \'./res/user.js\';\\nimport postResource from \'./res/posts.js\';\\nimport contentImageResource from \'./res/content-image.js\';\\nimport httpProxy from \'http-proxy\';\\n\\ndeclare var process : {\\n  env: {\\n    DATABASE_URL: string\\n    NODE_ENV: string,\\n    AWS_S3_BUCKET: string,\\n    AWS_S3_REGION: string,\\n  }\\n  argv: string[]\\n}\\n\\nexport const admin = new AdminForth({\\n  baseUrl: \'/admin\',\\n  auth: {\\n    usersResourceId: \'user\',  // resource to get user during login\\n    usernameField: \'email\',  // field where username is stored, should exist in resource\\n    passwordHashField: \'passwordHash\',\\n  },\\n  customization: {\\n    brandName: \'My Admin\',\\n    datesFormat: \'D MMM\',\\n    timeFormat: \'HH:mm\',\\n    emptyFieldPlaceholder: \'-\',\\n    styles: {\\n      colors: {\\n        light: {\\n          // color for links, icons etc.\\n          primary: \'rgb(47 37 227)\',\\n          // color for sidebar and text\\n          sidebar: {main:\'#EFF5F7\', text:\'#333\'},\\n        },\\n      }\\n    }\\n  },\\n  dataSources: [{\\n    id: \'maindb\',\\n    url:  process.env.DATABASE_URL?.replace(\'file:\', \'sqlite://\'),\\n  }],\\n  resources: [\\n    userResource,\\n    postResource,\\n    contentImageResource,\\n  ],\\n  menu: [\\n    {\\n      homepage: true,\\n      label: \'Posts\',\\n      icon: \'flowbite:home-solid\',\\n      resourceId: \'post\',\\n    },\\n    { type: \'gap\' },\\n    { type: \'divider\' },\\n    { type: \'heading\', label: \'SYSTEM\' },\\n    {\\n      label: \'Users\',\\n      icon: \'flowbite:user-solid\',\\n      resourceId: \'user\',\\n    }\\n  ],\\n});\\n\\n\\nif (import.meta.url === `file://${process.argv[1]}`) {\\n  // if script is executed directly e.g. node index.ts or npm start\\n\\n  const app = express()\\n  app.use(express.json());\\n  const port = 3500;\\n\\n  // needed to compile SPA. Call it here or from a build script e.g. in Docker build time to reduce downtime\\n  if (process.env.NODE_ENV === \'development\') {\\n    await admin.bundleNow({ hotReload: true });\\n  }\\n  console.log(\'Bundling AdminForth done. For faster serving consider calling bundleNow() from a build script.\');\\n\\n  // api to server recent posts\\n  app.get(\'/api/posts\', async (req, res) => {\\n    const { offset = 0, limit = 100, slug = null } = req.query;\\n    const posts = await admin.resource(\'post\').list(\\n      [Filters.EQ(\'published\', true), ...(slug ? [Filters.LIKE(\'slug\', slug)] : [])],\\n      limit,\\n      offset,\\n      Sorts.DESC(\'createdAt\'),\\n    );\\n    const authorIds = [...new Set(posts.map((p: any) => p.authorId))];\\n    const authors = (await admin.resource(\'user\').list(Filters.IN(\'id\', authorIds)))\\n      .reduce((acc: any, a: any) => {acc[a.id] = a; return acc;}, {});\\n    posts.forEach((p: any) => {\\n      const author = authors[p.authorId];\\n      p.author = { \\n        publicName: author.publicName, \\n        avatar: `https://${process.env.AWS_S3_BUCKET}.s3.${process.env.AWS_S3_REGION}.amazonaws.com/${author.avatar}`\\n      };\\n      p.picture = `https://${process.env.AWS_S3_BUCKET}.s3.${process.env.AWS_S3_REGION}.amazonaws.com/${p.picture}`;\\n    });\\n    res.json(posts);\\n  });\\n\\n  // here we proxy all non-/admin requests to nuxt instance http://localhost:3000\\n  // this is done for demo purposes, in production you should do this using high-performance reverse proxy like traefik or nginx\\n  app.use((req, res, next) => {\\n    if (!req.url.startsWith(\'/admin\')) {\\n      const proxy = httpProxy.createProxyServer();\\n      proxy.on(\'error\', function (err, req, res) {\\n        res.send(`No response from Nuxt at http://localhost:3000, did you start it? ${err}`)\\n      });\\n      proxy.web(req, res, { target: \'http://localhost:3000\' });\\n    } else {\\n      next();\\n    }\\n  });\\n\\n  // serve after you added all api\\n  admin.express.serve(app)\\n\\n  admin.discoverDatabases().then(async () => {\\n    if (!await admin.resource(\'user\').get([Filters.EQ(\'email\', \'adminforth@adminforth.dev\')])) {\\n      await admin.resource(\'user\').create({\\n        email: \'adminforth@adminforth.dev\',\\n        passwordHash: await AdminForth.Utils.generatePasswordHash(\'adminforth\'),\\n      });\\n    }\\n  });\\n\\n  admin.express.listen(port, () => {\\n    console.log(`\\\\n\u26a1 AdminForth is available at http://localhost:${port}\\\\n`)\\n  });\\n}\\n```\\n\\n## Step 5: Create resources\\n\\nCreate `res` folder. Create `./res/user.ts` file with following content:\\n\\n```ts title=\\"./res/users.ts\\"\\nimport AdminForth, { AdminForthDataTypes } from \'adminforth\';\\nimport { randomUUID } from \'crypto\';\\nimport UploadPlugin from \'@adminforth/upload\';\\n\\nexport default {\\n  dataSource: \'maindb\',\\n  table: \'user\',\\n  label: \'Users\',\\n  recordLabel: (r: any) => `\ud83d\udc64 ${r.email}`,\\n  columns: [\\n    {\\n      name: \'id\',\\n      primaryKey: true,\\n      fillOnCreate: () => randomUUID(),\\n      showIn: [\'list\', \'filter\', \'show\'],\\n    },\\n    {\\n      name: \'email\',\\n      required: true,\\n      isUnique: true,\\n      enforceLowerCase: true,\\n      validation: [\\n        AdminForth.Utils.EMAIL_VALIDATOR,\\n      ],\\n      type: AdminForthDataTypes.STRING,\\n    },\\n    {\\n      name: \'createdAt\',\\n      type: AdminForthDataTypes.DATETIME,\\n      showIn: [\'list\', \'filter\', \'show\'],\\n      fillOnCreate: () => (new Date()).toISOString(),\\n    },\\n    {\\n      name: \'password\',\\n      virtual: true,\\n      required: { create: true },\\n      editingNote: { edit: \'Leave empty to keep password unchanged\' },\\n      minLength: 8,\\n      type: AdminForthDataTypes.STRING,\\n      showIn: [\'create\', \'edit\'],\\n      masked: true,\\n      validation: [\\n        // request to have at least 1 digit, 1 upper case, 1 lower case\\n        AdminForth.Utils.PASSWORD_VALIDATORS.UP_LOW_NUM,\\n      ],\\n    },\\n    { name: \'passwordHash\', backendOnly: true, showIn: [] },\\n    { \\n      name: \'publicName\',\\n      type: AdminForthDataTypes.STRING,\\n    },\\n    { name: \'avatar\' },\\n  ],\\n  hooks: {\\n    create: {\\n      beforeSave: async ({ record, adminUser, resource }) => {\\n        record.passwordHash = await AdminForth.Utils.generatePasswordHash(record.password);\\n        return { ok: true };\\n      }\\n    },\\n    edit: {\\n      beforeSave: async ({ record, adminUser, resource }) => {\\n        if (record.password) {\\n          record.passwordHash = await AdminForth.Utils.generatePasswordHash(record.password);\\n        }\\n        return { ok: true }\\n      },\\n    },\\n  }\\n  plugins: [\\n    new UploadPlugin({\\n      pathColumnName: \'avatar\',\\n      s3Bucket: process.env.AWS_S3_BUCKET,\\n      s3Region: process.env.AWS_S3_REGION,\\n      allowedFileExtensions: [\'jpg\', \'jpeg\', \'png\', \'gif\', \'webm\',\'webp\'],\\n      maxFileSize: 1024 * 1024 * 20, // 20MB\\n      s3AccessKeyId: process.env.AWS_ACCESS_KEY_ID,\\n      s3SecretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,\\n      s3ACL: \'public-read\', // ACL which will be set to uploaded file\\n      s3Path: (\\n        { originalFilename, originalExtension }: {originalFilename: string, originalExtension: string }\\n      ) => `user-avatars/${new Date().getFullYear()}/${randomUUID()}/${originalFilename}.${originalExtension}`,\\n      generation: {\\n        provider: \'openai-dall-e\',\\n        countToGenerate: 2,\\n        openAiOptions: {\\n          model: \'dall-e-3\',\\n          size: \'1024x1024\',\\n          apiKey: process.env.OPENAI_API_KEY,\\n        },\\n      },\\n    }),\\n  ],\\n}\\n```\\n\\n\\nCreate `posts.ts` file in res directory with following content:\\n\\n```ts title=\\"./res/post.ts\\"\\nimport { AdminUser, AdminForthDataTypes } from \'adminforth\';\\nimport { randomUUID } from \'crypto\';\\nimport UploadPlugin from \'@adminforth/upload\';\\nimport RichEditorPlugin from \'@adminforth/rich-editor\';\\nimport ChatGptPlugin from \'@adminforth/chat-gpt\';\\nimport slugify from \'slugify\';\\n\\nexport default {\\n  table: \'post\',\\n  dataSource: \'maindb\',\\n  label: \'Posts\',\\n  recordLabel: (r: any) => `\ud83d\udcdd ${r.title}`,\\n  columns: [\\n    {\\n      name: \'id\',\\n      primaryKey: true,\\n      fillOnCreate: () => randomUUID(),\\n      showIn: [\'filter\', \'show\'],\\n    },\\n    {\\n      name: \'title\',\\n      required: true,\\n      showIn: [\'list\', \'create\', \'edit\', \'filter\', \'show\'],\\n      maxLength: 255,\\n      minLength: 3,\\n      type: AdminForthDataTypes.STRING,\\n    },\\n    {\\n      name: \'picture\',\\n      showIn: [\'list\', \'create\', \'edit\', \'filter\', \'show\'],\\n    },\\n    {\\n      name: \'slug\',\\n      showIn: [\'filter\', \'show\'],\\n    },\\n    {\\n      name: \'content\',\\n      showIn: [\'create\', \'edit\', \'filter\', \'show\'],\\n      type: AdminForthDataTypes.RICHTEXT,\\n    },\\n    {\\n      name: \'createdAt\',\\n      showIn: [\'list\', \'filter\', \'show\',],\\n      fillOnCreate: () => (new Date()).toISOString(),\\n    },\\n    {\\n      name: \'published\',\\n      required: true,\\n    },\\n    {\\n      name: \'authorId\',\\n      foreignResource: {\\n        resourceId: \'user\',\\n      },\\n      showIn: [\'filter\', \'show\'],\\n      fillOnCreate: ({ adminUser }: { adminUser: AdminUser }) => {\\n        return adminUser.dbUser.id;\\n      }\\n    }\\n  ],\\n  hooks: {\\n    create: {\\n      beforeSave: async ({ record, adminUser }: { record: any, adminUser: AdminUser }) => {\\n        record.slug = slugify(record.title, { lower: true });\\n        return { ok: true };\\n      },\\n    },\\n    edit: {\\n      beforeSave: async ({ record, adminUser }: { record: any, adminUser: AdminUser }) => {\\n        if (record.title) {\\n          record.slug = slugify(record.title, { lower: true });\\n        }\\n        return { ok: true };\\n      },\\n    },\\n  },\\n  plugins: [\\n    new UploadPlugin({\\n      pathColumnName: \'picture\',\\n      s3Bucket: process.env.AWS_S3_BUCKET,\\n      s3Region: process.env.AWS_S3_REGION,\\n      allowedFileExtensions: [\'jpg\', \'jpeg\', \'png\', \'gif\', \'webm\',\'webp\'],\\n      maxFileSize: 1024 * 1024 * 20, // 20MB\\n      s3AccessKeyId: process.env.AWS_ACCESS_KEY_ID,\\n      s3SecretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,\\n      s3ACL: \'public-read\', // ACL which will be set to uploaded file\\n      s3Path: (\\n        { originalFilename, originalExtension }: {originalFilename: string, originalExtension: string }\\n      ) => `post-previews/${new Date().getFullYear()}/${randomUUID()}/${originalFilename}.${originalExtension}`,\\n      generation: {\\n        provider: \'openai-dall-e\',\\n        countToGenerate: 2,\\n        openAiOptions: {\\n          model: \'dall-e-3\',\\n          size: \'1792x1024\',\\n          apiKey: process.env.OPENAI_API_KEY,\\n        },\\n        fieldsForContext: [\'title\'],\\n      },\\n    }),\\n    new RichEditorPlugin({\\n      htmlFieldName: \'content\',\\n      completion: {\\n        provider: \'openai-chat-gpt\',\\n        params: {\\n          apiKey: process.env.OPENAI_API_KEY,\\n          model: \'gpt-4o\',\\n        },\\n        expert: {\\n          debounceTime: 250,\\n        }\\n      }, \\n      attachments: {\\n        attachmentResource: \'contentImage\',\\n        attachmentFieldName: \'img\',\\n        attachmentRecordIdFieldName: \'postId\',\\n        attachmentResourceIdFieldName: \'resourceId\',\\n      },\\n    }),\\n    new ChatGptPlugin({\\n      openAiApiKey: process.env.OPENAI_API_KEY,\\n      model: \'gpt-4o\',\\n      fieldName: \'title\',\\n      expert: {\\n        debounceTime: 250,\\n      }\\n    }),\\n  ]\\n}\\n```\\n\\nAlso create `content-image.ts` file in `res` directory with following content:\\n\\n```ts title=\\"./res/content-image.ts\\"\\n\\nimport { AdminForthDataTypes } from \'adminforth\';\\nimport { randomUUID } from \'crypto\';\\nimport UploadPlugin from \'@adminforth/upload\';\\n\\nexport default {\\n  table: \'contentImage\',\\n  dataSource: \'maindb\',\\n  label: \'Content Images\',\\n  recordLabel: (r: any) => `\ud83d\uddbc\ufe0f ${r.img}`,\\n  columns: [\\n    {\\n      name: \'id\',\\n      primaryKey: true,\\n      fillOnCreate: () => randomUUID(),\\n    },\\n    {\\n      name: \'createdAt\',\\n      type: AdminForthDataTypes.DATETIME,\\n      fillOnCreate: () => (new Date()).toISOString(),\\n    },\\n    {\\n      name: \'img\',\\n      type: AdminForthDataTypes.STRING,\\n      required: true,\\n    },\\n    {\\n      name: \'postId\',\\n      foreignResource: {\\n        resourceId: \'post\',\\n      },\\n      showIn: [\'list\', \'filter\', \'show\'],\\n    },\\n    {\\n      name: \'resourceId\',\\n    }\\n  ],\\n  plugins: [\\n    new UploadPlugin({\\n      pathColumnName: \'img\',\\n      s3Bucket: process.env.AWS_S3_BUCKET,\\n      s3Region: process.env.AWS_S3_REGION,\\n      allowedFileExtensions: [\'jpg\', \'jpeg\', \'png\', \'gif\', \'webm\',\'webp\'],\\n      maxFileSize: 1024 * 1024 * 20, // 20MB\\n      s3AccessKeyId: process.env.AWS_ACCESS_KEY_ID,\\n      s3SecretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,\\n      s3ACL: \'public-read\', // ACL which will be set to uploaded file\\n      s3Path: (\\n        { originalFilename, originalExtension }: {originalFilename: string, originalExtension: string }\\n      ) => `post-content/${new Date().getFullYear()}/${randomUUID()}/${originalFilename}.${originalExtension}`,\\n    }),\\n  ],\\n}\\n```\\n\\nNow you can start your admin panel:\\n\\n```bash\\nnpm start\\n```\\n\\nOpen `http://localhost:3500/admin` in your browser and login with `adminforth@adminforth.dev` and `adminforth` credentials.\\nSet up your avatar (you can generate it with AI) and public name in user settings.\\n\\n![alt text](aiblogpost.png)\\n\\n## Step 5: Create Nuxt project\\n\\n\\nNow let\'s initialize our seo-facing frontend:\\n\\n```bash\\nnpx nuxi@latest init seo\\ncd seo\\nnpm install -D sass-embedded\\nnpm run dev\\n```\\n\\nEdit `app.vue`: \\n\\n```html title=\\"./seo/app.vue\\"\\n<template>\\n  <div id=\\"app\\">\\n    <NuxtPage />\\n  </div>\\n</template>\\n\\n\\n<style lang=\\"scss\\">\\n\\n$grColor1: #74E1FF;\\n$grColor2: #8580B4;\\n$grColor3: #5E53C3;\\n$grColor4: #4FC7E9;\\n$grColor5: #695BE9;\\n\\n  #app {\\n    font-family: Avenir, Helvetica, Arial, sans-serif;\\n    -webkit-font-smoothing: antialiased;\\n    -moz-osx-font-smoothing: grayscale;\\n    // gradient with color spots\\n    animation: gradient 15s ease infinite;\\n    min-height: 100vh;\\n  }\\n  body {\\n    margin: 0;\\n    padding: 0;\\n    max-height: 100vh;\\n    overflow: overlay;\\n    background-image: radial-gradient(\\n  circle farthest-corner at top left, $grColor1 0%, rgba(225, 243, 97,0) 50%),\\n      radial-gradient(\\n      circle farthest-side at top right, $grColor2 0%, rgba(181, 176, 177,0) 10%),\\n      radial-gradient(circle farthest-corner at bottom right, $grColor3 0%, rgba(204, 104, 119, 0) 33%),\\n      radial-gradient(\\n          circle farthest-corner at top right, $grColor4 0%, rgba(155, 221, 240,0) 50%),\\n      radial-gradient(ellipse at bottom center, $grColor5 0%, rgba(254, 43, 0, 0) 80%); \\n    background-attachment: fixed;\\n  }\\n</style>\\n```\\n\\n\\nAdd folder `pages` and create `index.vue`:\\n\\n```html title=\\"./seo/pages/index.vue\\"\\n<template>\\n  <div class=\\"container\\">\\n    <PostCard \\n      v-for=\\"post in posts\\" \\n      :key=\\"post.id\\" \\n      :post=\\"post\\"\\n    />\\n    <div class=\\"no-posts\\" v-if=\\"!posts.length\\">\\n      No posts added yet\\n      <a href=\\"/admin\\">Add a first one in admin</a>\\n    </div>\\n  </div>\\n</template>\\n\\n<style lang=\\"scss\\">\\n.container {\\n  display: flex;\\n  justify-content: center;\\n  align-items: center;\\n  flex-wrap: wrap;\\n  flex-direction: column;\\n  gap: 1rem;\\n  padding-top: 2rem;\\n}\\n\\n.no-posts {\\n  margin-top: 2rem;\\n  font-size: 1.5rem;\\n  text-align: center;\\n  background-color: rgba(255 244 255 / 0.43);\\n  padding: 2rem;\\n  border-radius: 0.5rem;\\n  border: 1px solid #FFFFFF;\\n  box-shadow: 0.2rem 0.3rem 2rem rgba(0, 0, 0, 0.1);\\n  color: #555;\\n  a {\\n    color: #333;\\n    text-decoration: underline;\\n    margin-top: 1rem;\\n    display: block;\\n    font-size: 1.2rem;\\n  }\\n\\n}\\n</style>\\n\\n<script lang=\\"ts\\" setup>\\n\\nimport PostCard from \'~/PostCard.vue\'\\n\\nconst posts = ref([])\\n\\nonMounted(async () => {\\n  const resp = await fetch(`/api/posts`);\\n  posts.value = await resp.json();\\n})\\n\\n<\/script>\\n```\\n\\nFinally, create `PostCard.vue` component:\\n\\n```html title=\\"./seo/PostCard.vue\\"\\n<template>\\n  <div class=\\"post-card\\">\\n    <img v-if=\\"props.post.picture\\" :src=\\"props.post.picture\\" alt=\\"post image\\" />\\n    <h2>{{ props.post.title }}</h2>\\n    <div class=\\"content\\" v-html=\\"props.post.content\\"></div>\\n    <div class=\\"posted-at\\">\\n      <div>{{ formatDate(props.post.createdAt) }}</div>\\n      <div class=\\"author\\">\\n        <img :src=\\"props.post.author.avatar\\" alt=\\"author avatar\\" />\\n        <div>\\n          {{ props.post.author.publicName }}\\n        </div>\\n      </div>\\n    </div>\\n  </div>\\n</template>\\n\\n<script setup lang=\\"ts\\">\\n\\nconst props = defineProps<{\\n  post: {\\n    title: string\\n    content: string\\n    createdAt: string // iso date\\n    picture?: string\\n    author: {\\n      publicName: string\\n      avatar: string\\n    }\\n  }\\n}>()\\n\\n\\nfunction formatDate(date: string) {\\n  // format to format MMM DD, YYYY using Intl.DateTimeFormat\\n  return new Intl.DateTimeFormat(\'en-US\', {\\n    month: \'short\',\\n    day: \'2-digit\',\\n    year: \'numeric\'\\n  }).format(new Date(date))\\n}\\n<\/script>\\n\\n<style lang=\\"scss\\">\\n\\n.post-card {\\n  background-color: rgba(255 244 255 / 0.43);\\n  padding: 2rem;\\n  border-radius: 0.5rem;\\n  border: 1px solid #FFFFFF;\\n  box-shadow: 0.2rem 0.3rem 2rem rgba(0, 0, 0, 0.1);\\n  max-width: calc(100vw - 4rem);\\n  width: 600px;\\n  color: #333;\\n  line-height: 1.8rem;\\n\\n  >img {\\n    width: 100%;\\n    border-radius: 0.5rem;\\n    margin-bottom: 2rem;\\n  }\\n  \\n  h2 {\\n    margin: 0 0 2rem 0;\\n    font-size: 1.5rem;\\n  }\\n\\n  .content {\\n    margin-top: 1rem;\\n  }\\n\\n  .posted-at {\\n    margin-top: 1rem;\\n    font-size: 0.8rem;\\n    color: #666;\\n    display: flex;\\n    justify-content: space-between;\\n    align-items: center;\\n  }\\n\\n  .author {\\n    display: flex;\\n    align-items: center;\\n\\n    img {\\n      width: 2rem;\\n      height: 2rem;\\n      border-radius: 50%;\\n      margin-right: 0.5rem;\\n    }\\n    div {\\n      // flash wire dot line effect\\n      position: relative;\\n      overflow: hidden;\\n      border-radius: 1rem;\\n      padding: 0.2rem 0.5rem;\\n      font-size: 1rem;\\n      background: linear-gradient(90deg, rgb(0 21 255) 0%, rgb(0 0 0) 100%);\\n      background-size: 200% auto;\\n      background-clip: text;\\n      -webkit-background-clip: text;\\n      color: transparent; /* Hide the original text color */\\n      animation: shimmer 2s infinite;\\n      @keyframes shimmer {\\n        0% {\\n          background-position: -200% center;\\n        }\\n        100% {\\n          background-position: 200% center;\\n        }\\n      }\\n\\n    }\\n  }\\n\\n}\\n\\n</style>\\n```\\n\\nNow you can start your Nuxt project:\\n\\n```bash\\nnpm run dev\\n```\\n\\nAnd run `npm start` if you did not run it previously:\\n\\n```bash\\nnpm start\\n```\\n\\nOpen `http://localhost:3500` in your browser and you will see your blog with posts from admin panel:\\n\\n![alt text](localhost_3500_.png)\\n\\nGo to `http://localhost:3500/admin` to add new posts.\\n\\n## Step 6: Deploy\\n\\nWe will dockerize app to make it easy to deploy with many ways. We will wrap both Node.js adminforth app and Nuxt.js app into single container for simplicity using supervisor. However you can split them into two containers and deploy them separately e.g. using docker compose. \\n\\nPlease note that in this demo example we routing requests to Nuxt.js app from AdminForth app using http-proxy. \\nWhile this will work fine, it might give slower serving then if you would route traffik using dedicated reverse proxies like traefik or nginx.\\n\\n\\n### Dockerize in single container\\n\\nCreate `bundleNow.ts` file in root project directory:\\n\\n```ts title=\\"./bundleNow.ts\\"\\nimport { admin } from \'./index.js\';\\n\\nawait admin.bundleNow({ hotReload: false});\\nconsole.log(\'Bundling AdminForth done.\');\\n```\\n\\n\\nCreate `Dockerfile` in root project directory:\\n\\n```dockerfile title=\\"./Dockerfile\\"\\nFROM node:20-alpine\\nEXPOSE 3500\\nWORKDIR /app\\nRUN apk add --no-cache supervisor\\nCOPY package.json package-lock.json ./\\nRUN npm ci\\nCOPY seo/package.json seo/package-lock.json seo/\\nRUN cd seo && npm ci\\nCOPY . .\\n\\nRUN npx tsx bundleNow.ts\\nRUN cd seo && npm run build\\n\\nRUN cat > /etc/supervisord.conf <<EOF\\n[supervisord]\\nnodaemon=true\\n\\n[program:app]\\ncommand=npm run startLive\\ndirectory=/app\\nautostart=true\\nautorestart=true\\nstdout_logfile=/dev/stdout\\nstderr_logfile=/dev/stderr\\n\\n[program:seo]\\ncommand=sh -c \\"cd seo && node .output/server/index.mjs\\"\\ndirectory=/app\\nautostart=true\\nautorestart=true\\nstdout_logfile=/dev/stdout\\nstderr_logfile=/dev/stderr\\n\\n[program:prisma]\\ncommand=npx --yes prisma migrate deploy\\ndirectory=/app\\nautostart=true\\nstdout_logfile=/dev/stdout\\nstderr_logfile=/dev/stderr\\n\\nEOF\\n\\nCMD [\\"supervisord\\", \\"-c\\", \\"/etc/supervisord.conf\\"]\\n```\\n\\nCreate `.dockerignore` file in root project directory:\\n\\n```bash title=\\".dockerignore\\"\\n.env\\nnode_modules\\nseo/node_modules\\n.git\\ndb\\n*.tar\\n.terraform*\\nterraform*\\n*.tf\\n```\\n\\n\\nBuild and run your docker container locally:\\n\\n```bash\\nsudo docker run -p80:3500 -v ./prodDb:/app/db --env-file .env -it $(docker build -q .)\\n```\\n\\nNow you can open `http://localhost` in your browser and see your blog.\\n\\n### Deploy to EC2 with terraform\\n\\n\\nFirst of all install Terraform as described here [terraform installation](https://developer.hashicorp.com/terraform/install#linux).\\n\\nIf you are on Ubuntu(WSL2 or native) you can use the following commands:\\n\\n```bash\\nwget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg\\necho \\"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\\" | sudo tee /etc/apt/sources.list.d/hashicorp.list\\nsudo apt update && sudo apt install terraform\\n```\\n\\n\\nCreate special AWS credentials for deployemnts by going to `AWS console` -> `IAM` -> `Users` -> `Add user` (e.g. my-ai-blog-user) -> Attach existing policies directly -> `AdministratorAccess` -> Create user. Save `Access key ID` and `Secret access key` into `~/.aws/credentials` file:\\n\\nCreate or open file:\\n\\n```bash\\ncode ~/.aws/credentials\\n```\\n\\n```bash\\n...\\n\\n[myaws]\\naws_access_key_id = YOUR_ACCESS_KEY\\naws_secret_access_key = YOUR_SECRET\\n```\\n\\n\\nCreate file `main.tf` in root project directory:\\n\\n```hcl title=\\"./main.tf\\"\\nprovider \\"aws\\" {\\n  region = \\"eu-central-1\\"\\n  profile = \\"myaws\\"\\n}\\n\\ndata \\"aws_ami\\" \\"amazon_linux\\" {\\n  most_recent = true\\n  owners      = [\\"amazon\\"]\\n\\n  filter {\\n    name   = \\"name\\"\\n    values = [\\"amzn2-ami-hvm-*-x86_64-gp2\\"]\\n  }\\n}\\n\\ndata \\"aws_vpc\\" \\"default\\" {\\n  default = true\\n}\\n\\ndata \\"aws_subnet\\" \\"default_subnet\\" {\\n  filter {\\n    name   = \\"vpc-id\\"\\n    values = [data.aws_vpc.default.id]\\n  }\\n\\n  filter {\\n    name   = \\"default-for-az\\"\\n    values = [\\"true\\"]\\n  }\\n\\n  filter {\\n    name   = \\"availability-zone\\"\\n    values = [\\"eu-central-1a\\"]\\n  }\\n}\\n\\nresource \\"aws_security_group\\" \\"instance_sg\\" {\\n  name   = \\"my-ai-blog-instance-sg\\"\\n  vpc_id = data.aws_vpc.default.id\\n\\n  ingress {\\n    description = \\"Allow HTTP\\"\\n    from_port   = 80\\n    to_port     = 80\\n    protocol    = \\"tcp\\"\\n    cidr_blocks = [\\"0.0.0.0/0\\"]\\n  }\\n\\n  # SSH\\n  ingress {\\n    description = \\"Allow SSH\\"\\n    from_port   = 22\\n    to_port     = 22\\n    protocol    = \\"tcp\\"\\n    cidr_blocks = [\\"0.0.0.0/0\\"]\\n  }\\n\\n  egress {\\n    description = \\"Allow all outbound traffic\\"\\n    from_port   = 0\\n    to_port     = 0\\n    protocol    = \\"-1\\"\\n    cidr_blocks = [\\"0.0.0.0/0\\"]\\n  }\\n}\\n\\nresource \\"aws_key_pair\\" \\"deployer\\" {\\n  key_name   = \\"terraform-deployer-key\\"\\n  public_key = file(\\"~/.ssh/id_rsa.pub\\") # Path to your public SSH key\\n}\\n\\n\\nresource \\"aws_instance\\" \\"docker_instance\\" {\\n  ami                    = data.aws_ami.amazon_linux.id\\n  instance_type          = \\"t3a.micro\\"\\n  subnet_id              = data.aws_subnet.default_subnet.id\\n  vpc_security_group_ids = [aws_security_group.instance_sg.id]\\n  key_name               = aws_key_pair.deployer.key_name\\n\\n  # prevent accidental termination of ec2 instance and data loss\\n  # if you will need to recreate the instance still (not sure why it can be?), you will need to remove this block manually by next command:\\n  # > terraform taint aws_instance.app_instance\\n  lifecycle {\\n    prevent_destroy = true\\n    ignore_changes = [ami]\\n  }\\n\\n  user_data = <<-EOF\\n    #!/bin/bash\\n    yum update -y\\n    amazon-linux-extras install docker -y\\n    systemctl start docker\\n    systemctl enable docker\\n    usermod -a -G docker ec2-user\\n  EOF\\n\\n  tags = {\\n    Name = \\"my-ai-blog-instance\\"\\n  }\\n}\\n\\nresource \\"null_resource\\" \\"build_image\\" {\\n  provisioner \\"local-exec\\" {\\n    command = \\"docker build -t blogapp . && docker save blogapp:latest -o blogapp_image.tar\\"\\n  }\\n  triggers = {\\n    always_run = timestamp() # Force re-run if necessary\\n  }\\n}\\n\\nresource \\"null_resource\\" \\"remote_commands\\" {\\n  depends_on = [aws_instance.docker_instance, null_resource.build_image]\\n\\n  triggers = {\\n    always_run = timestamp()\\n  }\\n\\n\\n  provisioner \\"file\\" {\\n    source      = \\"${path.module}/blogapp_image.tar\\"\\n    destination = \\"/home/ec2-user/blogapp_image.tar\\"\\n    \\n    connection {\\n      type        = \\"ssh\\"\\n      user        = \\"ec2-user\\"\\n      private_key = file(\\"~/.ssh/id_rsa\\")\\n      host        = aws_instance.docker_instance.public_ip\\n    }\\n  }\\n\\n  provisioner \\"file\\" {\\n    source      = \\"${path.module}/.env\\"\\n    destination = \\"/home/ec2-user/.env\\"\\n    \\n    connection {\\n      type        = \\"ssh\\"\\n      user        = \\"ec2-user\\"\\n      private_key = file(\\"~/.ssh/id_rsa\\")\\n      host        = aws_instance.docker_instance.public_ip\\n    }\\n  }\\n\\n  provisioner \\"remote-exec\\" {\\n    inline = [\\n      \\"while ! command -v docker &> /dev/null; do echo \'Waiting for Docker to be installed...\'; sleep 1; done\\",\\n      \\"while ! sudo docker info &> /dev/null; do echo \'Waiting for Docker to start...\'; sleep 1; done\\",\\n      \\"sudo docker system prune -af\\",\\n      \\"docker load -i /home/ec2-user/blogapp_image.tar\\",\\n      \\"sudo docker rm -f blogapp || true\\",\\n      \\"sudo docker run --env-file .env -d -p 80:3500 --name blogapp -v /home/ec2-user/db:/app/db blogapp\\"\\n    ]\\n\\n    connection {\\n      type        = \\"ssh\\"\\n      user        = \\"ec2-user\\"\\n      private_key = file(\\"~/.ssh/id_rsa\\")\\n      host        = aws_instance.docker_instance.public_ip\\n    }\\n  }\\n\\n  \\n}\\n\\noutput \\"instance_public_ip\\" {\\n  value = aws_instance.docker_instance.public_ip\\n}\\n\\n```\\n\\n\\nNow you can deploy your app to AWS EC2:\\n\\n```bash\\nterraform init\\nterraform apply -auto-approve\\n```\\n\\n> \u261d\ufe0f To destroy and  stop billing run `terraform destroy -auto-approve`\\n\\n> \u261d\ufe0f To check logs run `ssh -i ~/.ssh/id_rsa ec2-user@$(terraform output instance_public_ip)`, then `sudo docker logs -n100 -f aiblog`\\n\\nTerraform config will build Docker image locally and then copy it to EC2 instance. This approach allows to save build resources (CPU/RAM) on EC2 instance, however increases network traffic (image might be around 200MB). If you want to build image on EC2 instance, you can adjust config slightly: remove `null_resource.build_image` and change `null_resource.remote_commands` to build image on EC2 instance, however micro instance most likely will not be able to build and keep app running at the same time, so you will need to increase instance type or terminate app while building image (which introduces downtime so not recommended as well).\\n\\n\\n### Add HTTPs and CDN\\n\\nFor adding HTTPS and CDN you will use free Cloudflare service (though you can use paid AWS Cloudfront or any different way e.g. add Traefik and Let\'s Encrypt). Go to https://cloudflare.com and create an account. Add your domain and follow instructions to change your domain nameservers to Cloudflare ones.\\n\\nGo to your domain settings and add A record with your server IP address, which was shown in output of `terraform apply` command.\\n\\n```\\nType: A\\nName: blog\\nValue: x.y.z.w\\nCloudflare proxy: orange (enabled)\\n```\\n\\n![alt text](image.png)\\n\\n\\n## Useful links\\n\\n* [Full source code of the project](https://github.com/devforth/adminforth-example-ai-blog)\\n* [Live demo of AI BLog](https://blog-demo.adminforth.dev/admin/resource/post)\\n* [AdminForth documentation](https://adminforth.dev/docs/tutorial/gettingStarted/)\\n* [AdminForth GitHub](https://github.com/devforth/adminforth)\\n* [Nuxt.js documentation](https://nuxt.com/docs/getting-started/introduction)"},{"id":"chatgpt-plugin","metadata":{"permalink":"/blog/chatgpt-plugin","source":"@site/blog/2024-08-05-chatgpt/index.md","title":"Chat-GPT plugin to co-write texts and strings","description":"Couple of days ago we released a plugin which allows you to co-write texts and strings with the AI.","date":"2024-08-05T00:00:00.000Z","tags":[{"inline":false,"label":"ChatGPT","permalink":"/blog/tags/chatgpt","description":"ChatGPT is a conversational AI model that can generate human-like responses to text inputs."},{"inline":false,"label":"Plugin","permalink":"/blog/tags/plugin","description":"Plugins are extensions that add new features or functionality to a AdminForth."}],"readingTime":3.765,"hasTruncateMarker":false,"authors":[{"name":"Ivan Borshcho","title":"Maintainer of AdminForth","url":"https://github.com/ivictbor","imageURL":"https://avatars.githubusercontent.com/u/1838656?v=4","key":"ivanb","page":null}],"frontMatter":{"slug":"chatgpt-plugin","title":"Chat-GPT plugin to co-write texts and strings","authors":"ivanb","tags":["chatgpt","plugin"]},"unlisted":false,"prevItem":{"title":"Build AI-Assisted blog with AdminForth and Nuxt in 20 minutes","permalink":"/blog/ai-blog"}},"content":"Couple of days ago we released a plugin which allows you to co-write texts and strings with the AI. \\n\\nToday LLM is already a must tool to speed-up writing, brainstorming, or generating ideas.\\n\\nHere is how it looks in action:\\n\\n![alt text](../../docs/tutorial/05-Plugins/demoChatGpt.gif)\\n\\n## Simple controls\\n\\nTo control plugin we use our open-source [vue-suggestion-input](https://github.com/devforth/vue-suggestion-input).\\nIt allows to:\\n* Complete suggestion with `Tab`.\\n* Complete word with `Ctrl + Right`.\\n* Regenerate suggestion with `Ctrl + Down`.\\n* On mobile suggestion word is accepted with swipe right on the screen.\\n\\n## Want to try it out?\\n\\nGo to a [Live Demo](https://demo.adminforth.dev/resource/aparts/create) and start creating a new apartment record. Type in the `title` and `description` field and see how the plugin works.\\n\\nIf you want to try it out on your hello-wrold admin panel, then, first follow the instructions in the [Getting Started](/docs/tutorial/gettingStarted) tutorial to create a new project. To install the plugin, then, follow the instructions in the [Chat-GPT plugin page](/docs/tutorial/Plugins/text-complete).\\n\\n\\n## Context matters, but with sane limit!\\n\\nWhen the prompts are called, the plugin passes to LLM not only previous text in current field to complete, but also passes values of other fields in record edited. This allows to generate more relevant completions. \\nFor example if you have a record with fields `title` and `description`, and you are editing `description`, the plugin will pass `title` value to LLM as well.\\n\\nBut obviously longer prompts lead to higher LLM costs and longer response times. That is why we created mechanics to limit the length of prompts passed to LLM.\\n\\nLimitation is done on 2 levels:\\n- plugin settings have `expert.promptInputLimit` - limits length of edited field passed to LLM. If field is longer, it will pass only last `promptInputLimit` characters.\\n- plugin settings have `expert.recordContext` which defines limits for other fields in record. Each field can\'t be longer then `maxFieldLength` (default is 300). If field is longer then it is split to parts `splitParts` and they are joined with \'...\'. Also if there are more non-empty fields then `maxFields`, then plugin selects top longest `maxFields` fields to pass to LLM.\\n\\nIn the end, total number of characters passed to LLM is limited by formula:\\n\\n```\\npromptInputLimit + maxFields * maxFieldLength + <LLM request static part>\\n```\\n\\nWhere `<LLM request static part>` is a constant part of request to LLM which looks like this:\\n\\n```\\nContinue writing for text/string field \\"${this.options.fieldName}\\" in the table \\"${resLabel}\\"\\\\n\\nRecord has values for the context: ${inputContext}\\\\n\\nCurrent field value: ${currentVal}\\\\n\\nDon\'t talk to me. Just write text. No quotes. Don\'t repeat current field value, just write completion\\\\n\\n```\\n\\n## Model configuration\\n\\nOf course you can define which model to use for completion. By default plugin uses `gpt-4o-mini` model ($0.150 / 1M input tokens, $0.600 / 1M output tokens for Aug 2024). But you can change it to any other model available in OpenAI API. More powerful replacement is `gpt-4o` model ($5.00 / 1M input tokens, $15.00 / 1M output tokens for Aug 2024).\\n\\nAlso you can define other parameters for completion like:\\n- `maxTokens` - most likely you don\'t want to waste tokens on longer completions, so default is 50 tokens.\\n- `temperature` - model temperature, default is 0.7. You can increase it to get more creative completions (but with risk of getting nonsense). Or decrease it to get more conservative completions.\\n- `debounceTime` - debounce time in milliseconds, default is 300. After typing each character, plugin waits for `debounceTime` milliseconds before sending request to LLM. If new character is typed during this time, then timer is reset. This is done to prevent sending too many requests to LLM.\\n\\n## Frontend story\\n\\nWhen we were working on plugin, we wanted to make it as user-friendly as possible. \\n\\nMost frontend packages for completion have old-fashioned dropdowns, which are not very convenient to use.\\n\\nWe wanted to have something very similar to Copilot or Google doc. So we created our own package [vue-suggestion-input](https://github.com/devforth/vue-suggestion-input). It is also MIT and open-source so you can use it in your projects as well.\\n\\nUnder the hood vue-suggestion-input uses [quill](https://quilljs.com/) editor. Quill is one of the WYSIWYG editors which have really good\\nAPI to work with DOM inside of editor. Basically all pieces of content in editor are represented as so called blots. And best thing - you can create your own custom blot. So we created our own blot which is responsible for rendering completion suggestion. Then you just \\"dance\\" around positioning of selection, suggestion and text modification, and thees things are easy-peasy with quill API."}]}}')}}]);
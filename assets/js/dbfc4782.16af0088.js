"use strict";(self.webpackChunkadminforth=self.webpackChunkadminforth||[]).push([[8749],{1895:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"ai-blog","metadata":{"permalink":"/blog/ai-blog","source":"@site/blog/2024-10-01-ai-blog/index.md","title":"AI-Assisted blog with AdminForth and Nuxt in a minutes","description":"Many developers today are using copilots to write code faster and think less about syntax.","date":"2024-10-01T00:00:00.000Z","tags":[{"inline":true,"label":"nuxt","permalink":"/blog/tags/nuxt"},{"inline":false,"label":"ChatGPT","permalink":"/blog/tags/chatgpt","description":"ChatGPT is a conversational AI model that can generate human-like responses to text inputs."}],"readingTime":3.445,"hasTruncateMarker":false,"authors":[{"name":"Ivan Borshcho","title":"Maintainer of AdminForth","url":"https://github.com/ivictbor","imageURL":"https://avatars.githubusercontent.com/u/1838656?v=4","key":"ivanb"}],"frontMatter":{"slug":"ai-blog","title":"AI-Assisted blog with AdminForth and Nuxt in a minutes","authors":"ivanb","tags":["nuxt","chatgpt"]},"unlisted":false,"nextItem":{"title":"Chat-GPT plugin to co-write texts and strings","permalink":"/blog/chatgpt-plugin"}},"content":"Many developers today are using copilots to write code faster and think less about syntax.\\n\\nBut what about writing plain text? For example blogs and micro-blogs? Sometimes you want to share your progress and thoughts but you are lazy for typing. Then you can give a try to AI-assisted blogging. Our Open-Source AdminForth framework has couple of new AI-capable plugins to write text and generate images.\\n\\nFor AI plugins are backed by OpenAI API, but their architecture allows to be easily extended for other AI providers once OpenAI competitors will reach the same or better level of quality.\\n\\nHere we will suggest you simple as 1-2-3 steps to build and host a blog with AI assistant which will help you to write posts.\\n\\nOur tech stack will include:\\n\\n- [Nuxt.js](https://nuxt.com/) - SEO-friendly page rendering framework\\n- [AdminForth](https://adminforth.dev/) - Admin panel framework for creating posts\\n- [AdminForth RichEditor plugin](https://adminforth.dev/docs/tutorial/Plugins/RichEditor/) - WYSIWYG editor with AI assistant in Copilot style\\n- Node and typescript\\n- Prisma for migrations\\n- SQLite for database, though you can easily switch it to Postgres or MongoDB\\n\\n## Prerequirements\\n\\nWe will use Node v20, if you not have it installed, we recommend [NVM](https://github.com/nvm-sh/nvm?tab=readme-ov-file#install--update-script)\\n\\n```bash\\nnvm install 20\\nnvm alias default 20\\nnvm use 20\\n```\\n\\n## Step 1: Create a new AdminForth project\\n\\n```bash\\nmkdir ai-blog\\ncd ai-blog\\nnpm init -y\\nnpm install adminforth @adminforth/upload @adminforth/rich-editor express slugify @types/express typescript tsx @types/node  --save-dev\\nnpx --yes tsc --init --module ESNext --target ESNext\\n```\\n\\n## Step 2: Prepare environment\\n\\n### OpenAI\\n\\nTo allocate OpenAI API key, go to https://platform.openai.com/, open Dashboard -> API keys -> Create new secret key.\\n\\n### S3\\n\\n1. Go to https://aws.amazon.com and login.\\n2. Go to Services -> S3 and create a bucket. Put in bucket name e.g. `my-ai-blog-bucket`. \\nLeave all settings unchanged (ACL Disabled, Block all public access - checked)\\n3. Go to bucket settings, Permissions, scroll down to Cross-origin resource sharing (CORS) and put in the following configuration:\\n\\n```json\\n[\\n    {\\n        \\"AllowedHeaders\\": [\\n            \\"*\\"\\n        ],\\n        \\"AllowedMethods\\": [\\n            \\"PUT\\"\\n        ],\\n        \\"AllowedOrigins\\": [\\n            \\"http://localhost:3500\\"\\n        ],\\n        \\"ExposeHeaders\\": []\\n    }\\n]\\n```\\n\\n> \u261d\ufe0f In AllowedOrigins add all your domains. For example if you will serve blog and admin on `https://example.com/` you should add \\n> `\\"https://example.com\\"` to AllowedOrigins:\\n>\\n> ```json\\n> [\\n>      \\"https://example.com\\",\\n>      \\"http://localhost:3500\\"\\n> ]\\n> ```\\n> Every character matters, so don\'t forget to add `http://` or `https://`!\\n\\n4. Go to Services -> IAM and create a new user. Put in user name e.g. `my-ai-blog-bucket`.\\n5. Attach existing policies directly -> `AmazonS3FullAccess`. Go to your user -> `Add permissions` -> `Attach policies directly` -> `AmazonS3FullAccess`\\n6. Go to Security credentials and create a new access key. Save `Access key ID` and `Secret access key`.\\n\\n\\n### Create .env file in project directory\\n\\nCreate `.env` file with the following content:\\n\\n```bash title=\\".env\\"\\nDATABASE_URL=file:./db.sqlite\\nADMINFORTH_SECRET=123\\nNODE_ENV=development\\n# Your OpenAI API key for ChatGPT completions\\nOPENAI_API_KEY=...\\nAWS_ACCESS_KEY_ID=your_access_key_id\\nAWS_SECRET_ACCESS_KEY=your_secret_access_key\\nAWS_S3_BUCKET=my-ai-blog-bucket\\nAWS_S3_REGION=us-east-1\\n```\\n\\n\\n## Step 3: Initialize database\\n\\nCreate `./schema.prisma` and put next content there:\\n\\n\\n```yaml title=\\"./schema.prisma\\" \\ngenerator client {\\n  provider = \\"prisma-client-js\\"\\n}\\n\\ndatasource db {\\n  provider = \\"sqlite\\"\\n  url      = env(\\"DATABASE_URL\\")\\n}\\n\\nmodel User {\\n  id           String     @id\\n  createdAt    DateTime \\n  email        String   @unique\\n  avatar       String?\\n  publicName   String?\\n  passwordHash String\\n  posts        Post[]\\n}\\n\\nmodel Post {\\n  id          String     @id\\n  createdAt   DateTime \\n  title       String\\n  slug        String\\n  picture     String?\\n  content     String\\n  published   Boolean  \\n  author      User?    @relation(fields: [authorId], references: [id])\\n  authorId    String?\\n  contentImages ContentImage[]\\n}\\n\\nmodel ContentImage {\\n  id         String     @id\\n  createdAt  DateTime \\n  img        String\\n  postId     String\\n  resourceId String\\n  post       Post      @relation(fields: [postId], references: [id])\\n}\\n```\\n\\nCreate database using `prisma migrate`:\\n\\n```bash\\nnpx -y prisma migrate dev --name init\\n```\\n\\n## Step 4: Setting up AdminForth\\n\\n\\nOpen `package.json`, set `type` to `module` and add `start` script:\\n\\n```json title=\\"./package.json\\"\\n{\\n  ...\\n//diff-add\\n  \\"type\\": \\"module\\",\\n  \\"scripts\\": {\\n    ...\\n//diff-add\\n    \\"start\\": \\"tsx watch --env-file=.env index.ts\\"\\n  },\\n}\\n```\\n\\nCreate `index.ts` file in root directory with following content:\\n\\n```ts title=\\"./index.ts\\"\\n\\n```\\n\\n## Step 5: Create resources\\n\\nCreate `users.res.ts` file in root directory with following content:\\n\\n```ts title=\\"./users.res.ts\\"\\n\\n```\\n\\n\\nCreate `posts.res.ts` file in root directory with following content:\\n\\n```ts title=\\"./posts.res.ts\\"\\n\\n\\n```\\n\\n\\n\\n\\nInit Nuxt project in `front` directory:\\n\\n```bash\\nnpx -y nuxi@latest init front\\n```"},{"id":"chatgpt-plugin","metadata":{"permalink":"/blog/chatgpt-plugin","source":"@site/blog/2024-08-05-chatgpt/index.md","title":"Chat-GPT plugin to co-write texts and strings","description":"Couple of days ago we released a plugin which allows you to co-write texts and strings with the AI.","date":"2024-08-05T00:00:00.000Z","tags":[{"inline":false,"label":"ChatGPT","permalink":"/blog/tags/chatgpt","description":"ChatGPT is a conversational AI model that can generate human-like responses to text inputs."},{"inline":false,"label":"Plugin","permalink":"/blog/tags/plugin","description":"Plugins are extensions that add new features or functionality to a AdminForth."}],"readingTime":3.765,"hasTruncateMarker":false,"authors":[{"name":"Ivan Borshcho","title":"Maintainer of AdminForth","url":"https://github.com/ivictbor","imageURL":"https://avatars.githubusercontent.com/u/1838656?v=4","key":"ivanb"}],"frontMatter":{"slug":"chatgpt-plugin","title":"Chat-GPT plugin to co-write texts and strings","authors":"ivanb","tags":["chatgpt","plugin"]},"unlisted":false,"prevItem":{"title":"AI-Assisted blog with AdminForth and Nuxt in a minutes","permalink":"/blog/ai-blog"}},"content":"Couple of days ago we released a plugin which allows you to co-write texts and strings with the AI. \\n\\nToday LLM is already a must tool to speed-up writing, brainstorming, or generating ideas.\\n\\nHere is how it looks in action:\\n\\n![alt text](../../docs/tutorial/05-Plugins/demoChatGpt.gif)\\n\\n## Simple controls\\n\\nTo control plugin we use our open-source [vue-suggestion-input](https://github.com/devforth/vue-suggestion-input).\\nIt allows to:\\n* Complete suggestion with `Tab`.\\n* Complete word with `Ctrl + Right`.\\n* Regenerate suggestion with `Ctrl + Down`.\\n* On mobile suggestion word is accepted with swipe right on the screen.\\n\\n## Want to try it out?\\n\\nGo to a [Live Demo](https://demo.adminforth.dev/resource/aparts/create) and start creating a new apartment record. Type in the `title` and `description` field and see how the plugin works.\\n\\nIf you want to try it out on your hello-wrold admin panel, then, first follow the instructions in the [Getting Started](https://adminforth.dev/docs/tutorial/gettingStarted) tutorial to create a new project. To install the plugin, then, follow the instructions in the [Chat-GPT plugin page](https://adminforth.dev/docs/tutorial/Plugins/chat-gpt).\\n\\n\\n## Context matters, but with sane limit!\\n\\nWhen the prompts are called, the plugin passes to LLM not only previous text in current field to complete, but also passes values of other fields in record edited. This allows to generate more relevant completions. \\nFor example if you have a record with fields `title` and `description`, and you are editing `description`, the plugin will pass `title` value to LLM as well.\\n\\nBut obviously longer prompts lead to higher LLM costs and longer response times. That is why we created mechanics to limit the length of prompts passed to LLM.\\n\\nLimitation is done on 2 levels:\\n- plugin settings have `expert.promptInputLimit` - limits length of edited field passed to LLM. If field is longer, it will pass only last `promptInputLimit` characters.\\n- plugin settings have `expert.recordContext` which defines limits for other fields in record. Each field can\'t be longer then `maxFieldLength` (default is 300). If field is longer then it is split to parts `splitParts` and they are joined with \'...\'. Also if there are more non-empty fields then `maxFields`, then plugin selects top longest `maxFields` fields to pass to LLM.\\n\\nIn the end, total number of characters passed to LLM is limited by formula:\\n\\n```\\npromptInputLimit + maxFields * maxFieldLength + <LLM request static part>\\n```\\n\\nWhere `<LLM request static part>` is a constant part of request to LLM which looks like this:\\n\\n```\\nContinue writing for text/string field \\"${this.options.fieldName}\\" in the table \\"${resLabel}\\"\\\\n\\nRecord has values for the context: ${inputContext}\\\\n\\nCurrent field value: ${currentVal}\\\\n\\nDon\'t talk to me. Just write text. No quotes. Don\'t repeat current field value, just write completion\\\\n\\n```\\n\\n## Model configuration\\n\\nOf course you can define which model to use for completion. By default plugin uses `gpt-4o-mini` model ($0.150 / 1M input tokens, $0.600 / 1M output tokens for Aug 2024). But you can change it to any other model available in OpenAI API. More powerful replacement is `gpt-4o` model ($5.00 / 1M input tokens, $15.00 / 1M output tokens for Aug 2024).\\n\\nAlso you can define other parameters for completion like:\\n- `maxTokens` - most likely you don\'t want to waste tokens on longer completions, so default is 50 tokens.\\n- `temperature` - model temperature, default is 0.7. You can increase it to get more creative completions (but with risk of getting nonsense). Or decrease it to get more conservative completions.\\n- `debounceTime` - debounce time in milliseconds, default is 300. After typing each character, plugin waits for `debounceTime` milliseconds before sending request to LLM. If new character is typed during this time, then timer is reset. This is done to prevent sending too many requests to LLM.\\n\\n## Frontend story\\n\\nWhen we were working on plugin, we wanted to make it as user-friendly as possible. \\n\\nMost frontend packages for completion have old-fashioned dropdowns, which are not very convenient to use.\\n\\nWe wanted to have something very similar to Copilot or Google doc. So we created our own package [vue-suggestion-input](https://github.com/devforth/vue-suggestion-input). It is also MIT and open-source so you can use it in your projects as well.\\n\\nUnder the hood vue-suggestion-input uses [quill](https://quilljs.com/) editor. Quill is one of the WYSIWYG editors which have really good\\nAPI to work with DOM inside of editor. Basically all pieces of content in editor are represented as so called blots. And best thing - you can create your own custom blot. So we created our own blot which is responsible for rendering completion suggestion. Then you just \\"dance\\" around positioning of selection, suggestion and text modification, and thees things are easy-peasy with quill API."}]}}')}}]);
"use strict";(self.webpackChunkadminforth=self.webpackChunkadminforth||[]).push([[2469],{1191:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var s=t(1450),i=t(4848),r=t(8453);const o={slug:"compose-ec2-deployment-github-actions-registry",title:"IaaC Simplified: Automating EC2 Deployments with GitHub Actions, Terraform, Docker & Distribution Registry",authors:"ivanb",tags:["aws","terraform","github-actions"],description:"The ultimate step-by-step guide to cost-effective, build-time-efficient, and easy managable EC2 deployments using GitHub Actions, Terraform, Docker, and a self-hosted registry.",image:"/ogs/ga-tf-aws.jpg"},a="Building on CI versus building on EC2?",c={authorsImageUrls:[void 0]},l=[{value:"Chellenges when you build on CI",id:"chellenges-when-you-build-on-ci",level:2},{value:"Delivering images",id:"delivering-images",level:3},{value:"Exporing images to tar files",id:"exporing-images-to-tar-files",level:4},{value:"Docker registry",id:"docker-registry",level:4},{value:"Persisting cache",id:"persisting-cache",level:3},{value:"Registry authorization and traffic encryption",id:"registry-authorization-and-traffic-encryption",level:3},{value:"Step 1 - Dockerfile",id:"step-1---dockerfile",level:2},{value:"Step 2 - compose.yml",id:"step-2---composeyml",level:2},{value:"Step 3 - create a SSH keypair",id:"step-3---create-a-ssh-keypair",level:2},{value:"Step 4 - create TLS certificates to encrypt traffic between CI and registry",id:"step-4---create-tls-certificates-to-encrypt-traffic-between-ci-and-registry",level:2},{value:"Step 5 - .gitignore file",id:"step-5---gitignore-file",level:2},{value:"Step 6 - buildx bake file",id:"step-6---buildx-bake-file",level:2},{value:"Step 7 - main terraform file main.tf",id:"step-7---main-terraform-file-maintf",level:2},{value:"Step 7.1 - Configure AWS Profile",id:"step-71---configure-aws-profile",level:3},{value:"Step 7.2 - Run deployment",id:"step-72---run-deployment",level:3},{value:"Step 8 - Migrate state to the cloud",id:"step-8---migrate-state-to-the-cloud",level:2},{value:"Step 9 - CI/CD - Github Actions",id:"step-9---cicd---github-actions",level:2},{value:"Step 8.1 - Add secrets to GitHub",id:"step-81---add-secrets-to-github",level:3},{value:"Adding secrets",id:"adding-secrets",level:3},{value:"Out of space on EC2 instance? Extend EBS volume",id:"out-of-space-on-ec2-instance-extend-ebs-volume",level:3}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"alt text",src:t(4582).A+"",width:"1200",height:"630"})}),"\n",(0,i.jsx)(n.p,{children:"This guide shows how to deploy own Docker apps (with AdminForth as example) to Amazon EC2 instance with Docker and Terraform involving Docker self-hosted registry."}),"\n",(0,i.jsx)(n.p,{children:"Needed resources:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["GitHub actions Free plan which includes 2000 minutes per month (1000 of 2-minute builds per month - more then enough for many projects, if you are not running tests etc). Extra builds would cost ",(0,i.jsx)(n.code,{children:"0.008$"})," per minute."]}),"\n",(0,i.jsxs)(n.li,{children:["AWS account where we will auto-spawn EC2 instance. We will use ",(0,i.jsx)(n.code,{children:"t3a.small"})," instance (2 vCPUs, 2GB RAM) which costs ",(0,i.jsx)(n.code,{children:"~14$"})," per month in ",(0,i.jsx)(n.code,{children:"us-east-1"})," region (cheapest region). Also it will take ",(0,i.jsx)(n.code,{children:"$2"})," per month for EBS gp2 storage (20GB) for EC2 instance"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This is it, registry will be auto-spawned on EC2 instance, so no extra costs for it. Also GitHub storage is not used, so no extra costs for it."}),"\n",(0,i.jsx)(n.p,{children:"The setup has next features:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Build process is done using IaaC approach with HashiCorp Terraform, so almoast no manual actions are needed from you. Every resource including EC2 server instance is described in code which is commited to repo so no manual clicks are needed."}),"\n",(0,i.jsx)(n.li,{children:"Docker build process is done on GitHub actions, so EC2 server is not overloaded"}),"\n",(0,i.jsx)(n.li,{children:"Changes in infrastructure including changing server type, adding S3 Bucket, changing size of sever disk is also can be done by commiting code to repo."}),"\n",(0,i.jsx)(n.li,{children:"Docker images and cache are stored on EC2 server, so no extra costs for Docker registry are needed."}),"\n",(0,i.jsx)(n.li,{children:"Total build time for average commit to AdminForth app (with Vite rebuilds) is around 2 minutes."}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Previously we had a blog post about ",(0,i.jsx)(n.a,{href:"/blog/compose-ec2-deployment-github-actions/",children:"deploying AdminForth to EC2 with Terraform without registry"}),". That method might work well but has a significant disadvantage - build process happens on EC2 itself and uses EC2 RAM and CPU. This can be a problem if your EC2 instance is well-loaded without extra free resources. Moreover, low-end EC2 instances have a small amount of RAM and CPU, so build process which involves vite/tsc/etc can be slow or even fail."]}),"\n",(0,i.jsx)(n.p,{children:"So obviously to solve this problem we need to move the build process to CI, however it introduces new chellenges and we will solve them in this post."}),"\n",(0,i.jsx)(n.p,{children:"Quick difference between approaches from previous post and current post:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Feature"}),(0,i.jsx)(n.th,{children:"Without Registry"}),(0,i.jsx)(n.th,{children:"With Registry"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"How and where docker build happens"}),(0,i.jsx)(n.td,{children:"Source code is rsync-ed from CI to EC2 and docker build is done there"}),(0,i.jsx)(n.td,{children:"Docker build is done on CI and docker image is pushed to registry (in this post we run registry automatically on EC2)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"How Docker build layers are cached"}),(0,i.jsx)(n.td,{children:"Cache is stored on EC2"}),(0,i.jsx)(n.td,{children:"GitHub actions has no own Docker cache out of the box, so it should be stored in dedicated place (we use self-hosted registry on the EC2 as it is free)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Advantages"}),(0,i.jsx)(n.td,{children:"Simpler setup with less code (we don't need code to run and secure registry, and don't need extra cache setup as is naturally persisted on EC2)."}),(0,i.jsx)(n.td,{children:"Build is done on CI, so EC2 server is not overloaded. For most cases CI builds are faster than on EC2. Plus time is saved because we don't need to rsync source code to EC2"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Disadvantages"}),(0,i.jsx)(n.td,{children:"Build on EC2 requires additional server RAM / overloads CPU"}),(0,i.jsx)(n.td,{children:"More terraform code is needed. registry cache might require small extra space on EC2"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"chellenges-when-you-build-on-ci",children:"Chellenges when you build on CI"}),"\n",(0,i.jsx)(n.p,{children:"A little bit of theory."}),"\n",(0,i.jsx)(n.p,{children:"When you move build process to CI you have to solve next chellenges:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"We need to deliver built docker images to EC2 somehow (and only we)"}),"\n",(0,i.jsx)(n.li,{children:"We need to persist cache between builds"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"delivering-images",children:"Delivering images"}),"\n",(0,i.jsx)(n.h4,{id:"exporing-images-to-tar-files",children:"Exporing images to tar files"}),"\n",(0,i.jsxs)(n.p,{children:["Simplest option which you can find is save docker images to tar files and deliver them to EC2. We can easily do it in terraform (using ",(0,i.jsx)(n.code,{children:"docker save -o ..."})," command on CI and ",(0,i.jsx)(n.code,{children:"docker load ..."})," command on EC2). However this option has a significant disadvantage - it is slow. Docker images are big (always include all layers, without any options), so it takes infinity to do save/load and another infinity to transfer them to EC2 (via relatively slow rsync/SSH and relatively slow GitHub actions outbound connection)."]}),"\n",(0,i.jsx)(n.h4,{id:"docker-registry",children:"Docker registry"}),"\n",(0,i.jsxs)(n.p,{children:["Faster, right option which we will use here - involve Docker registry. Registry is a repository which stores docker images. It does it in a smart way - it saves each image as several layers, so if you will update last layer, then only last layer will be pushed to registry and then only last will be pulled to EC2.\nTo give you row compare - whole-layers image might take ",(0,i.jsx)(n.code,{children:"1GB"}),", but last layer created by ",(0,i.jsx)(n.code,{children:"npm run build"})," command might take ",(0,i.jsx)(n.code,{children:"50MB"}),". And most builds you will do only last layer changes, so it will be 20 times faster to push/pull last layer than whole image.\nAnd this is not all, registry uses TLS HTTP protocol so it is faster then SSH/rsync encrypted connection."]}),"\n",(0,i.jsx)(n.p,{children:"Of course you have to care about a way of registry authentication (so only you and your CI/EC2 can push/pull images)."}),"\n",(0,i.jsx)(n.p,{children:"What docker registry can you use? Pretty known options:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Docker Hub - most famous. It is free for public images, so literally every opensource project uses it. However it is not free for private images, and you have to pay for it. In this post we are considering you might do development for commercial project with tight budget, so we will not use it."}),"\n",(0,i.jsx)(n.li,{children:"GHCR - Registry from Google. Has free plan but allows to store only 500MB and allows to transfer 1GB of traffic per month. Then you pay for every extra GB in storage and traffic. Probably small images will fit in this plan, but generally even alpine-based docker images are bigger than 500MB, so it is not a good option."}),"\n",(0,i.jsx)(n.li,{children:"Self-hosted registry web system. In our software development company, we use Harbor. It is a powerful free open-source registry that can be installed to own server. It allows pushing and pulling without limit. Also, it has internal life-cycle rules that cleanup unnecessary images and layers. The main drawbacks of it are that it is not so fast to install and configure, plus you have to get a domain and another powerfull server to run it. So unless you are a software development company, it is not worth using it."}),"\n",(0,i.jsxs)(n.li,{children:["Self-hosted minimal CNCF Distribution ",(0,i.jsx)(n.a,{href:"https://distribution.github.io/distribution/",children:"registry"})," on EC2 itself. So since we already have EC2, we can run registry on it directly. The ",(0,i.jsx)(n.code,{children:"registry"})," container is pretty light-weight and easy to setup and it will not consume a lot of extra CPU/RAM on server. Plus images will be stored close to application so pull will be fast."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"In the post we will use last (4th way). Our terraform will deploy registry automatically, so you don't have to do anything special."}),"\n",(0,i.jsx)(n.h3,{id:"persisting-cache",children:"Persisting cache"}),"\n",(0,i.jsx)(n.p,{children:"Docker builds without layer cache persistence are possible but very slow. Most builds only change a couple of layers, and having no ability to cache them will cause the Docker builder to regenerate all layers from scratch. This can, for example, increase the Docker build time from a minute to ten minutes or even more."}),"\n",(0,i.jsx)(n.p,{children:"Out of the box, GitHub Actions can't save Docker layers between builds, so you have to use external storage."}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"Though some CI systems can persist docker build cache, e.g. open-source self-hosted Woodpecker CI allows it out of the box. However GitHub actions which is pretty popular, reasonably can't allow such free storage to anyone"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"So when build-in Docker cache can't be used, there is one alternative - Docker BuildKit external cache.\nSo BuildKit allows you to connect external storage. There are several options, but most sweet for us is using Docker registry as cache storage (not only as images storage to deliver them to application server)."}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.em,{children:"BuildKit cache in Compose issue"}),"\nPreviously we used docker compose to build & run our app, it can be used to both build, push and pull images, but has ",(0,i.jsx)(n.a,{href:"https://github.com/docker/compose/issues/11072#issuecomment-1848974315",children:"issues with external cache connection"}),". While they are not solved we have to use ",(0,i.jsx)(n.code,{children:"docker buildx bake"})," command to build images. It is not so bad, but is another point of configuration which we will cover in this post."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"registry-authorization-and-traffic-encryption",children:"Registry authorization and traffic encryption"}),"\n",(0,i.jsx)(n.p,{children:"Hosting custom CNCF registry, from other hand is a security responsibility."}),"\n",(0,i.jsx)(n.p,{children:"If you don't protect it right, someone will be able to push any image to your registry and then pull it to your EC2 instance. This is a big security issue, so we have to protect our registry."}),"\n",(0,i.jsx)(n.p,{children:"First of all we need to set some authorization to our registry so everyone who will push/pull images will be authorized. Here we have 2 options: HTTP basic auth and Client certificate auth. We will use first one as it is easier to setup. We will generate basic login and password automatically in terraform so no extra actions are needed from you."}),"\n",(0,i.jsx)(n.p,{children:"But this is not enough. Basic auth is not encrypted, so someone can perform MITM attack and get your credentials. So we need to encrypt traffic between CI and registry. We can do it by using TLS certificates. So we will generate self-signed TLS certificates, and attach them to our registry."}),"\n",(0,i.jsx)(n.h1,{id:"practice---deploy-setup",children:"Practice - deploy setup"}),"\n",(0,i.jsxs)(n.p,{children:["Assume you have your AdminForth project in ",(0,i.jsx)(n.code,{children:"myadmin"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"step-1---dockerfile",children:"Step 1 - Dockerfile"}),"\n",(0,i.jsxs)(n.p,{children:["Create file ",(0,i.jsx)(n.code,{children:"Dockerfile"})," in ",(0,i.jsx)(n.code,{children:"myadmin"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-Dockerfile",metastring:'title="./myadmin/Dockerfile"',children:'# use the same node version which you used during dev\nFROM node:20-alpine\nWORKDIR /code/\nADD package.json package-lock.json /code/\nRUN npm ci  \nADD . /code/\nRUN --mount=type=cache,target=/tmp npx tsx bundleNow.ts\nCMD ["npm", "run", "startLive"]\n'})}),"\n",(0,i.jsx)(n.h2,{id:"step-2---composeyml",children:"Step 2 - compose.yml"}),"\n",(0,i.jsxs)(n.p,{children:["create folder ",(0,i.jsx)(n.code,{children:"deploy"})," and create file ",(0,i.jsx)(n.code,{children:"compose.yml"})," inside:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yml",metastring:'title="deploy/compose.yml"',children:'\nservices:\n  traefik:\n    image: "traefik:v2.5"\n    command:\n      - "--api.insecure=true"\n      - "--providers.docker=true"\n      - "--entrypoints.web.address=:80"\n    ports:\n      - "80:80"\n    volumes:\n      - "/var/run/docker.sock:/var/run/docker.sock:ro"\n\n  myadmin:\n    image: localhost:5000/myadmin:latest\n    pull_policy: always\n    restart: always\n    env_file:\n      - .env.live\n    volumes:\n      - myadmin-db:/code/db\n    labels:\n      - "traefik.enable=true"\n      - "traefik.http.routers.myadmin.rule=PathPrefix(`/`)"\n      - "traefik.http.services.myadmin.loadbalancer.server.port=3500"\n      - "traefik.http.routers.myadmin.priority=2"\n\nvolumes:\n  myadmin-db:\n'})}),"\n",(0,i.jsx)(n.h2,{id:"step-3---create-a-ssh-keypair",children:"Step 3 - create a SSH keypair"}),"\n",(0,i.jsxs)(n.p,{children:["Make sure you are still in ",(0,i.jsx)(n.code,{children:"deploy"})," folder, run next command:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",metastring:'title="deploy"',children:'mkdir .keys && ssh-keygen -f .keys/id_rsa -N ""\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Now it should create ",(0,i.jsx)(n.code,{children:"deploy/.keys/id_rsa"})," and ",(0,i.jsx)(n.code,{children:"deploy/.keys/id_rsa.pub"})," files with your SSH keypair. Terraform script will put the public key to the EC2 instance and will use private key to connect to the instance. Also you will be able to use it to connect to the instance manually."]}),"\n",(0,i.jsx)(n.h2,{id:"step-4---create-tls-certificates-to-encrypt-traffic-between-ci-and-registry",children:"Step 4 - create TLS certificates to encrypt traffic between CI and registry"}),"\n",(0,i.jsxs)(n.p,{children:["Make sure you are still in ",(0,i.jsx)(n.code,{children:"deploy"})," folder, run next command:"]}),"\n",(0,i.jsx)(n.p,{children:"Run next command to create TLS certificates:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'openssl req -new -x509 -days 3650 -newkey rsa:4096 -nodes -keyout .keys/ca.key -subj "/CN=My Custom CA" -out .keys/ca.pem\n'})}),"\n",(0,i.jsxs)(n.p,{children:["This will create ",(0,i.jsx)(n.code,{children:"deploy/.keys/ca.key"})," and ",(0,i.jsx)(n.code,{children:"deploy/.keys/ca.pem"})," files."]}),"\n",(0,i.jsx)(n.h2,{id:"step-5---gitignore-file",children:"Step 5 - .gitignore file"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"deploy/.gitignore"})," file with next content:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:".terraform/\n.keys/\n*.tfstate\n*.tfstate.*\n*.tfvars\ntfplan\n.env.live\n"})}),"\n",(0,i.jsx)(n.h2,{id:"step-6---buildx-bake-file",children:"Step 6 - buildx bake file"}),"\n",(0,i.jsxs)(n.p,{children:["Create file ",(0,i.jsx)(n.code,{children:"deploy/docker-bake.hcl"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-hcl",metastring:'title="deploy/docker-bake.hcl"',children:'variable "REGISTRY_BASE" {\n  default = "appserver.local:5000"\n}\n\ngroup "default" {\n  target = "myadmin"\n}\n\ntarget "myadmin" {\n  context = "../myadmin"\n  tags = ["${REGISTRY_BASE}/myadmin:latest"]\n  cache-from = ["type=registry,ref=${REGISTRY_BASE}/myadmin:cache"]\n  cache-to   = ["type=registry,ref=${REGISTRY_BASE}/myadmin:cache,mode=max,compression=zstd"]\n  push = true\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"step-7---main-terraform-file-maintf",children:"Step 7 - main terraform file main.tf"}),"\n",(0,i.jsxs)(n.p,{children:["First of all install Terraform as described here ",(0,i.jsx)(n.a,{href:"https://developer.hashicorp.com/terraform/install#linux",children:"terraform installation"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["Create file ",(0,i.jsx)(n.code,{children:"main.tf"})," in ",(0,i.jsx)(n.code,{children:"deploy"})," folder:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-hcl",metastring:'title="deploy/main.tf"',children:'\nlocals {\n  app_name = "<your_app_name>"\n  aws_region = "us-east-1"\n}\n\n\nprovider "aws" {\n  region = local.aws_region\n  profile = "myaws"\n}\n\ndata "aws_ami" "ubuntu_linux" {\n  most_recent = true\n  owners      = ["amazon"]\n\n  filter {\n    name   = "name"\n    values = ["ubuntu/images/hvm-ssd-gp3/ubuntu-noble-24.04-amd64-server-*"]\n  }\n}\n\ndata "aws_vpc" "default" {\n  default = true\n}\n\n\nresource "aws_eip" "eip" {\n domain = "vpc"\n}\nresource "aws_eip_association" "eip_assoc" {\n instance_id   = aws_instance.app_instance.id\n allocation_id = aws_eip.eip.id\n}\n\ndata "aws_subnet" "default_subnet" {\n  filter {\n    name   = "vpc-id"\n    values = [data.aws_vpc.default.id]\n  }\n\n  filter {\n    name   = "default-for-az"\n    values = ["true"]\n  }\n\n  filter {\n    name   = "availability-zone"\n    values = ["${local.aws_region}a"]\n  }\n}\n\nresource "aws_security_group" "instance_sg" {\n  name   = "${local.app_name}-instance-sg"\n  vpc_id = data.aws_vpc.default.id\n\n  ingress {\n    description = "Allow HTTP"\n    from_port   = 80\n    to_port     = 80\n    protocol    = "tcp"\n    cidr_blocks = ["0.0.0.0/0"]\n  }\n\n  ingress {\n    description = "Allow Docker registry"\n    from_port   = 5000\n    to_port     = 5000\n    protocol    = "tcp"\n    cidr_blocks = ["0.0.0.0/0"]\n  }\n\n  # SSH\n  ingress {\n    description = "Allow SSH"\n    from_port   = 22\n    to_port     = 22\n    protocol    = "tcp"\n    cidr_blocks = ["0.0.0.0/0"]\n  }\n\n  egress {\n    description = "Allow all outbound traffic"\n    from_port   = 0\n    to_port     = 0\n    protocol    = "-1"\n    cidr_blocks = ["0.0.0.0/0"]\n  }\n}\n\nresource "aws_key_pair" "app_deployer" {\n  key_name   = "terraform-deploy_${local.app_name}-key"\n  public_key = file("./.keys/id_rsa.pub") # Path to your public SSH key\n}\n\nresource "aws_instance" "app_instance" {\n  ami                    = data.aws_ami.ubuntu_linux.id\n  instance_type          = "t3a.small"  # just change it to another type if you need, check https://instances.vantage.sh/\n  subnet_id              = data.aws_subnet.default_subnet.id\n  vpc_security_group_ids = [aws_security_group.instance_sg.id]\n  key_name               = aws_key_pair.app_deployer.key_name\n\n  # prevent accidental termination of ec2 instance and data loss\n  # if you will need to recreate the instance still (not sure why it can be?), you will need to remove this block manually by next command:\n  # > terraform taint aws_instance.app_instance\n  lifecycle {\n    prevent_destroy = true\n    ignore_changes = [ami]\n  }\n\n  root_block_device {\n    volume_size = 20 // Size in GB for root partition\n    volume_type = "gp2"\n    \n    # Even if the instance is terminated, the volume will not be deleted, delete it manually if needed\n    delete_on_termination = false\n  }\n\n  user_data = <<-EOF\n    #!/bin/bash\n    sudo apt-get update\n    sudo apt-get install ca-certificates curl\n    sudo install -m 0755 -d /etc/apt/keyrings\n    sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\n    sudo chmod a+r /etc/apt/keyrings/docker.asc\n\n    # Add the repository to Apt sources:\n    echo \\\n      "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n      $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \\\n      sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n    sudo apt-get update\n\n    sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin screen\n\n    systemctl start docker\n    systemctl enable docker\n    usermod -a -G docker ubuntu\n  EOF\n\n  tags = {\n    Name = "${local.app_name}-instance"\n  }\n}\n\nresource "null_resource" "setup_registry" {\n  provisioner "local-exec" {\n    command = <<-EOF\n      echo "Generating secret for local registry"\n      sha256sum ./.keys/id_rsa | cut -d \' \' -f1 | tr -d \'\\n\' > ./.keys/registry.pure\n\n      echo "Creating htpasswd file for local registry"\n      docker run --rm --entrypoint htpasswd httpd:2 -Bbn ci-user $(cat ./.keys/registry.pure) > ./.keys/registry.htpasswd\n\n      echo "Generating server certificate for registry"\n      openssl genrsa -out ./.keys/registry.key 4096\n      echo "subjectAltName=DNS:appserver.local,DNS:localhost,IP:127.0.0.1" > san.ext\n      openssl req -new -key ./.keys/registry.key -subj "/CN=appserver.local" -addext "$(cat san.ext)" -out ./.keys/registry.csr\n\n      openssl x509 -req -days 365 -CA ./.keys/ca.pem -CAkey ./.keys/ca.key -set_serial 01 -in ./.keys/registry.csr -extfile san.ext -out ./.keys/registry.crt \n\n      echo "Copying registry secret files to the instance"\n      rsync -t -avz -e "ssh -i ./.keys/id_rsa -o StrictHostKeyChecking=no" \\\n        ./.keys/registry.* ubuntu@${aws_eip_association.eip_assoc.public_ip}:/home/ubuntu/registry-auth\n    EOF\n  }\n\n  provisioner "remote-exec" {\n    inline = [<<-EOF\n      # wait for docker to be installed and started\n      bash -c \'while ! command -v docker &> /dev/null; do echo \\"Waiting for Docker to be installed...\\"; sleep 1; done\'\n      bash -c \'while ! docker info &> /dev/null; do echo \\"Waiting for Docker to start...\\"; sleep 1; done\'\n\n      # remove old registry if exists\n      docker rm -f registry\n      # run new registry\n      docker run -d --network host \\\n        --name registry \\\n        --restart always \\\n        -v /home/ubuntu/registry-data:/var/lib/registry \\\n        -v /home/ubuntu/registry-auth:/auth\\\n        -e "REGISTRY_AUTH=htpasswd" \\\n        -e "REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm" \\\n        -e "REGISTRY_AUTH_HTPASSWD_PATH=/auth/registry.htpasswd" \\\n        -e "REGISTRY_HTTP_TLS_CERTIFICATE=/auth/registry.crt" \\\n        -e "REGISTRY_HTTP_TLS_KEY=/auth/registry.key" \\\n        registry:2\n\n      EOF\n    ]\n\n    connection {\n      type        = "ssh"\n      user        = "ubuntu"\n      private_key = file("./.keys/id_rsa")\n      host        = aws_eip_association.eip_assoc.public_ip\n    }\n  }\n\n  triggers = {\n    always_run = 1 # change number to redeploy registry (if for some reason it was removed)\n  }\n}\n\n\nresource "null_resource" "sync_files_and_run" {\n\n  provisioner "local-exec" {\n    command = <<-EOF\n\n      # map appserver.local to the instance (in GA we don\'t know the IP, so have to use this mapping)\n      grep -q "appserver.local" /etc/hosts || echo "${aws_eip_association.eip_assoc.public_ip} appserver.local" | sudo tee -a /etc/hosts\n\n      # hosts modification may take some time to apply\n      sleep 5\n\n      # generate buildx authorization\n      sha256sum ./.keys/id_rsa | cut -d \' \' -f1 | tr -d \'\\n\' > ./.keys/registry.pure\n      echo \'{"auths":{"appserver.local:5000":{"auth":"\'$(echo -n "ci-user:$(cat ./.keys/registry.pure)" | base64 -w 0)\'"}}}\' > ~/.docker/config.json\n\n      echo "Running build"\n      docker buildx bake --progress=plain --push --allow=fs.read=..\n\n      # compose temporarily it is not working https://github.com/docker/compose/issues/11072#issuecomment-1848974315\n      # docker compose --progress=plain -p app -f ./compose.yml build --push\n\n      # if you will change host, pleasee add -o StrictHostKeyChecking=no\n      echo "Copy files to the instance" \n      rsync -t -avz -e "ssh -i ./.keys/id_rsa -o StrictHostKeyChecking=no" \\\n        --delete \\\n        --exclude \'.terraform\' \\\n        --exclude \'.keys\' \\\n        --exclude \'tfplan\' \\\n        . ubuntu@${aws_eip_association.eip_assoc.public_ip}:/home/ubuntu/app/deploy/\n\n      EOF\n  }\n\n  # Run docker compose after files have been copied\n  provisioner "remote-exec" {\n    inline = [<<-EOF\n      # wait for docker to be installed and started\n      bash -c \'while ! command -v docker &> /dev/null; do echo \\"Waiting for Docker to be installed...\\"; sleep 1; done\'\n      bash -c \'while ! docker info &> /dev/null; do echo \\"Waiting for Docker to start...\\"; sleep 1; done\'\n      \n      cat /home/ubuntu/registry-auth/registry.pure | docker login localhost:5000 -u ci-user --password-stdin\n        \n      cd /home/ubuntu/app/deploy\n\n      echo "Spinning up the app"\n      docker compose --progress=plain -p app -f compose.yml up -d --remove-orphans\n\n      # cleanup unused cache (run in background to not block terraform)\n      screen -dm docker system prune -f\n      screen -dm docker exec registry registry garbage-collect /etc/docker/registry/config.yml --delete-untagged=true \n    EOF\n    ]\n\n    connection {\n      type        = "ssh"\n      user        = "ubuntu"\n      private_key = file("./.keys/id_rsa")\n      host        = aws_eip_association.eip_assoc.public_ip\n    }\n  \n  }\n\n  # Ensure the resource is triggered every time based on timestamp or file hash\n  triggers = {\n    always_run = timestamp()\n  }\n\n  depends_on = [aws_instance.app_instance, aws_eip_association.eip_assoc, null_resource.setup_registry]\n}\n\n\noutput "instance_public_ip" {\n  value = aws_eip_association.eip_assoc.public_ip\n}\n\n\n######### META, tf state ##############\n\n\n# S3 bucket for storing Terraform state\nresource "aws_s3_bucket" "terraform_state" {\n  bucket = "${local.app_name}-terraform-state"\n}\n\nresource "aws_s3_bucket_lifecycle_configuration" "terraform_state" {\n  bucket = aws_s3_bucket.terraform_state.bucket\n\n  rule {\n    status = "Enabled"\n    id = "Keep only the latest version of the state file"\n\n    noncurrent_version_expiration {\n      noncurrent_days = 30\n    }\n  }\n}\n\nresource "aws_s3_bucket_versioning" "terraform_state" {\n  bucket = aws_s3_bucket.terraform_state.bucket\n\n  versioning_configuration {\n    status = "Enabled"\n  }\n}\n\nresource "aws_s3_bucket_server_side_encryption_configuration" "terraform_state" {\n  bucket = aws_s3_bucket.terraform_state.bucket\n\n  rule {\n    apply_server_side_encryption_by_default {\n      sse_algorithm     = "AES256"\n    }\n  }\n}\n\n\n'})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["\ud83d\udc46 Replace ",(0,i.jsx)(n.code,{children:"<your_app_name>"})," with your app name (no spaces, only underscores or letters)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"step-71---configure-aws-profile",children:"Step 7.1 - Configure AWS Profile"}),"\n",(0,i.jsxs)(n.p,{children:["Open or create file ",(0,i.jsx)(n.code,{children:"~/.aws/credentials"})," and add (if not already there):"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ini",children:"[myaws]\naws_access_key_id = <your_access_key>\naws_secret_access_key = <your_secret_key>\n"})}),"\n",(0,i.jsx)(n.h3,{id:"step-72---run-deployment",children:"Step 7.2 - Run deployment"}),"\n",(0,i.jsx)(n.p,{children:"To run the deployment first time, you need to run:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"terraform init\n"})}),"\n",(0,i.jsx)(n.p,{children:"Now run deployement:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"terraform apply -auto-approve\n"})}),"\n",(0,i.jsx)(n.h2,{id:"step-8---migrate-state-to-the-cloud",children:"Step 8 - Migrate state to the cloud"}),"\n",(0,i.jsx)(n.p,{children:"First deployment had to create S3 bucket for storing Terraform state. Now we need to migrate the state to the cloud."}),"\n",(0,i.jsxs)(n.p,{children:["Add to the end of ",(0,i.jsx)(n.code,{children:"main.tf"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-hcl",metastring:'title="main.tf"',children:'\n# Configure the backend to use the S3 bucket\nterraform {\n backend "s3" {\n   bucket         = "<your_app_name>-terraform-state"\n   key            = "state.tfstate"  # Define a specific path for the state file\n   region         = "us-east-1"\n   profile        = "myaws"\n   use_lockfile   = true\n }\n}\n'})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["\ud83d\udc46 Replace ",(0,i.jsx)(n.code,{children:"<your_app_name>"})," with your app name (no spaces, only underscores or letters).\nUnfortunately we can't use variables, HashiCorp thinks it is too dangerous \ud83d\ude25"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Now run:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"terraform init -migrate-state\n"})}),"\n",(0,i.jsx)(n.p,{children:"Now run test deployment:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"terraform apply -auto-approve\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Now you can delete local ",(0,i.jsx)(n.code,{children:"terraform.tfstate"})," file and ",(0,i.jsx)(n.code,{children:"terraform.tfstate.backup"})," file as they are in the cloud now."]}),"\n",(0,i.jsx)(n.h2,{id:"step-9---cicd---github-actions",children:"Step 9 - CI/CD - Github Actions"}),"\n",(0,i.jsxs)(n.p,{children:["Create file ",(0,i.jsx)(n.code,{children:".github/workflows/deploy.yml"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yml",metastring:'title=".github/workflows/deploy.yml"',children:'name: Deploy myadmin\nrun-name: ${{ github.actor }} builds myadmin \ud83d\ude80\non: [push]\njobs:\n  Explore-GitHub-Actions:\n    runs-on: ubuntu-latest\n\n    concurrency:\n      group: build-group\n      cancel-in-progress: false\n\n    steps:\n      - run: echo "\ud83c\udf89 The job was automatically triggered by a ${{ github.event_name }} event."\n      - run: echo "\ud83d\udc27 This job is now running on a ${{ runner.os }} server"\n      - run: echo "\ud83d\udd0e The name of your branch is ${{ github.ref }}"\n      - name: Check out repository code\n        uses: actions/checkout@v4\n\n      - name: Set up Terraform\n        uses: hashicorp/setup-terraform@v2\n        with:\n          terraform_version: 1.10.1 \n      \n      - name: Import Registry CA\n        run: |\n          mkdir -p deploy/.keys\n          echo "$VAULT_REGISTRY_CA_PEM" > deploy/.keys/ca.pem\n          echo "$VAULT_REGISTRY_CA_KEY" > deploy/.keys/ca.key\n        env:\n          VAULT_REGISTRY_CA_PEM: ${{ secrets.VAULT_REGISTRY_CA_PEM }}\n          VAULT_REGISTRY_CA_KEY: ${{ secrets.VAULT_REGISTRY_CA_KEY }}\n\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          buildkitd-config-inline: |\n            [registry."appserver.local:5000"]\n              ca=["deploy/.keys/ca.pem"]\n              \n          # use host network for resolving appserver.local\n          driver-opts: network=host\n\n      - name: Import registry SSH keys\n        run: |\n          mkdir -p deploy/.keys\n          echo "$VAULT_SSH_PRIVATE_KEY" > deploy/.keys/id_rsa\n          echo "$VAULT_SSH_PUBLIC_KEY" > deploy/.keys/id_rsa.pub\n          chmod 600 deploy/.keys/id_rsa*\n        env:\n          VAULT_SSH_PRIVATE_KEY: ${{ secrets.VAULT_SSH_PRIVATE_KEY }}\n          VAULT_SSH_PUBLIC_KEY: ${{ secrets.VAULT_SSH_PUBLIC_KEY }}\n\n      - name: Setup AWS credentials\n        run: |\n          mkdir -p ~/.aws\n          cat <<EOL > ~/.aws/credentials\n          [myaws]\n          aws_access_key_id=${VAULT_AWS_ACCESS_KEY_ID}\n          aws_secret_access_key=${VAULT_AWS_SECRET_ACCESS_KEY}\n          EOL\n        env:\n          VAULT_AWS_ACCESS_KEY_ID: ${{ secrets.VAULT_AWS_ACCESS_KEY_ID }}\n          VAULT_AWS_SECRET_ACCESS_KEY: ${{ secrets.VAULT_AWS_SECRET_ACCESS_KEY }}\n\n      - name: Terraform build\n        run: |\n          cd deploy\n          terraform init -reconfigure\n          # example of unlocking tf state if needed\n          # terraform force-unlock fb397548-8697-ea93-ab80-128a4f508fdf --force\n          terraform plan -out=tfplan \n          terraform apply tfplan \n                \n          \n      - run: echo "\ud83c\udf4f This job\'s status is ${{ job.status }}."\n'})}),"\n",(0,i.jsx)(n.h3,{id:"step-81---add-secrets-to-github",children:"Step 8.1 - Add secrets to GitHub"}),"\n",(0,i.jsxs)(n.p,{children:["Go to your GitHub repository, then ",(0,i.jsx)(n.code,{children:"Settings"})," -> ",(0,i.jsx)(n.code,{children:"Secrets"})," -> ",(0,i.jsx)(n.code,{children:"New repository secret"})," and add:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"VAULT_AWS_ACCESS_KEY_ID"})," - your AWS access key"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"VAULT_AWS_SECRET_ACCESS_KEY"})," - your AWS secret key"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"VAULT_SSH_PRIVATE_KEY"})," - execute ",(0,i.jsx)(n.code,{children:"cat ~/.ssh/id_rsa"})," and paste to GitHub secrets"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"VAULT_SSH_PUBLIC_KEY"})," - execute ",(0,i.jsx)(n.code,{children:"cat ~/.ssh/id_rsa.pub"})," and paste to GitHub secrets"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"VAULT_REGISTRY_CA_PEM"})," - execute ",(0,i.jsx)(n.code,{children:"cat deploy/.keys/ca.pem"})," and paste to GitHub secrets"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"VAULT_REGISTRY_CA_KEY"})," - execute ",(0,i.jsx)(n.code,{children:"cat deploy/.keys/ca.key"})," and paste to GitHub secrets"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Now you can push your changes to GitHub and see how it will be deployed automatically."}),"\n",(0,i.jsx)(n.h3,{id:"adding-secrets",children:"Adding secrets"}),"\n",(0,i.jsx)(n.p,{children:"Once you will have sensitive tokens/passwords in your apps you have to store them in a secure way."}),"\n",(0,i.jsx)(n.p,{children:"Simplest way is to use GitHub secrets."}),"\n",(0,i.jsxs)(n.p,{children:["Let's imagine you have ",(0,i.jsx)(n.code,{children:"OPENAI_API_KEY"})," which will be used one of AI-powered plugins of adminforth. We can't put this key to the code, so we have to store it in GitHub secrets."]}),"\n",(0,i.jsxs)(n.p,{children:["Open your GitHub repository, then ",(0,i.jsx)(n.code,{children:"Settings"})," -> ",(0,i.jsx)(n.code,{children:"Secrets"})," -> ",(0,i.jsx)(n.code,{children:"New repository secret"})," and add ",(0,i.jsx)(n.code,{children:"VAULT_OPENAI_API_KEY"})," with your key."]}),"\n",(0,i.jsxs)(n.p,{children:["Now open GitHub actions file and add it to the ",(0,i.jsx)(n.code,{children:"env"})," section:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yml",metastring:'title=".github/workflows/deploy.yml"',children:"      - name: Start building\n        env:\n          VAULT_AWS_ACCESS_KEY_ID: ${{ secrets.VAULT_AWS_ACCESS_KEY_ID }}\n          VAULT_AWS_SECRET_ACCESS_KEY: ${{ secrets.VAULT_AWS_SECRET_ACCESS_KEY }}\n          VAULT_SSH_PRIVATE_KEY: ${{ secrets.VAULT_SSH_PRIVATE_KEY }}\n          VAULT_SSH_PUBLIC_KEY: ${{ secrets.VAULT_SSH_PUBLIC_KEY }}\n//diff-add\n          VAULT_OPENAI_API_KEY: ${{ secrets.VAULT_OPENAI_API_KEY }}\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Next add it to the ",(0,i.jsx)(n.code,{children:"deploy.sh"})," script:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sh",metastring:'title="deploy/deploy.sh"',children:'//diff-remove\necho "" > .env.live\n//diff-add\ncat <<EOF > .env.live\n//diff-add\nOPENAI_API_KEY=$VAULT_OPENAI_API_KEY\n//diff-add\nEOF\n'})}),"\n",(0,i.jsx)(n.p,{children:"In the same way you can add any other secrets to your GitHub actions."}),"\n",(0,i.jsx)(n.h3,{id:"out-of-space-on-ec2-instance-extend-ebs-volume",children:"Out of space on EC2 instance? Extend EBS volume"}),"\n",(0,i.jsx)(n.p,{children:"To upgrade EBS volume size you have to do next steps:"}),"\n",(0,i.jsxs)(n.p,{children:["In ",(0,i.jsx)(n.code,{children:"main.tf"})," file:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-hcl",metastring:'title="main.tf"',children:'  root_block_device {\n//diff-remove\n    volume_size = 20 // Size in GB for root partition\n//diff-add\n    volume_size = 40 // Size in GB for root partition\n    volume_type = "gp2"\n  }\n'})}),"\n",(0,i.jsx)(n.p,{children:"And run build."}),"\n",(0,i.jsx)(n.p,{children:"This will increase physical size of EBS volume, but you have to increase filesystem size too."}),"\n",(0,i.jsx)(n.p,{children:"Login to EC2 instance:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ssh -i ./.keys/id_rsa ubuntu@<your_ec2_ip>\n"})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"You can find your EC2 IP in AWS console by visiting EC2 -> Instances -> Your instance -> IPv4 Public IP"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Now run next commands:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"lsblk\n"})}),"\n",(0,i.jsx)(n.p,{children:"This would show something like this:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"NAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\nloop0     7:0    0 99.4M  1 loop /snap/core/10908\nnvme0n1 259:0    0   40G  0 disk\n\u2514\u2500nvme0n1p1 259:1    0   20G  0 part /\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Here we see that ",(0,i.jsx)(n.code,{children:"nvme0n1"})," is our disk and ",(0,i.jsx)(n.code,{children:"nvme0n1p1"})," is our partition."]}),"\n",(0,i.jsx)(n.p,{children:"Now to extend partition run:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo growpart /dev/nvme0n1 1\nsudo resize2fs /dev/nvme0n1p1\n"})}),"\n",(0,i.jsx)(n.p,{children:"This will extend partition to the full disk size. No reboot is needed."})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},4582:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/ga-tf-aws-fd1b40a236f46c0ffc8c09ef37abaf38.jpg"},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var s=t(6540);const i={},r=s.createContext(i);function o(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(r.Provider,{value:n},e.children)}},1450:e=>{e.exports=JSON.parse('{"permalink":"/blog/compose-ec2-deployment-github-actions-registry","source":"@site/blog/2025-02-19-compose-ec2-deployment-ci-registry/index.md","title":"IaaC Simplified: Automating EC2 Deployments with GitHub Actions, Terraform, Docker & Distribution Registry","description":"The ultimate step-by-step guide to cost-effective, build-time-efficient, and easy managable EC2 deployments using GitHub Actions, Terraform, Docker, and a self-hosted registry.","date":"2025-02-19T00:00:00.000Z","tags":[{"inline":false,"label":"AWS","permalink":"/blog/tags/aws","description":"Amazon Web Services (AWS) is a cloud computing platform that provides a wide range of services for building and deploying applications."},{"inline":false,"label":"Terraform","permalink":"/blog/tags/terraform","description":"Terraform is an open-source infrastructure as code software tool created by HashiCorp that enables users to define and provision data center infrastructure using a declarative configuration language."},{"inline":false,"label":"GitHub Actions","permalink":"/blog/tags/github-actions","description":"GitHub Actions is a continuous integration and continuous deployment (CI/CD) service provided by GitHub that allows you to automate your software development workflows."}],"readingTime":19.45,"hasTruncateMarker":true,"authors":[{"name":"Ivan Borshchov","title":"Maintainer of AdminForth","url":"https://github.com/ivictbor","imageURL":"https://avatars.githubusercontent.com/u/1838656?v=4","key":"ivanb","page":null}],"frontMatter":{"slug":"compose-ec2-deployment-github-actions-registry","title":"IaaC Simplified: Automating EC2 Deployments with GitHub Actions, Terraform, Docker & Distribution Registry","authors":"ivanb","tags":["aws","terraform","github-actions"],"description":"The ultimate step-by-step guide to cost-effective, build-time-efficient, and easy managable EC2 deployments using GitHub Actions, Terraform, Docker, and a self-hosted registry.","image":"/ogs/ga-tf-aws.jpg"},"unlisted":false,"nextItem":{"title":"How I Open-Sourced My Secret Access Tokens from GitHub, Slack, and NPM \u2014 and Who Actually Cares","permalink":"/blog/how-i-opensourced-my-secret-tokens"}}')}}]);